<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=../preprocessing/ rel=prev><link href=../../tutorials/GettingStarted/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.16"><title>HMM Utils - nelpy</title><link rel=stylesheet href=../../assets/stylesheets/main.7e37652d.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#hmm-utils-api-reference class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title=nelpy class="md-header__button md-logo" aria-label=nelpy data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> nelpy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> HMM Utils </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=light data-md-color-primary=custom data-md-color-accent=custom aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/nelpy/nelpy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> nelpy/nelpy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../core/eventarray/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../tutorials/GettingStarted/ class=md-tabs__link> Tutorials </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=nelpy class="md-nav__button md-logo" aria-label=nelpy data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> nelpy </label> <div class=md-nav__source> <a href=https://github.com/nelpy/nelpy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> nelpy/nelpy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../core/eventarray/ class=md-nav__link> <span class=md-ellipsis> EventArray </span> </a> </li> <li class=md-nav__item> <a href=../core/analogsignalarray/ class=md-nav__link> <span class=md-ellipsis> AnalogSignalArray </span> </a> </li> <li class=md-nav__item> <a href=../core/intervalarray/ class=md-nav__link> <span class=md-ellipsis> IntervalArray </span> </a> </li> <li class=md-nav__item> <a href=../core/valeventarray/ class=md-nav__link> <span class=md-ellipsis> ValeventArray </span> </a> </li> <li class=md-nav__item> <a href=../core/coordinates/ class=md-nav__link> <span class=md-ellipsis> Coordinates </span> </a> </li> <li class=md-nav__item> <a href=../analysis/ class=md-nav__link> <span class=md-ellipsis> Analysis </span> </a> </li> <li class=md-nav__item> <a href=../auxiliary/ class=md-nav__link> <span class=md-ellipsis> Auxiliary </span> </a> </li> <li class=md-nav__item> <a href=../decoding/ class=md-nav__link> <span class=md-ellipsis> Decoding </span> </a> </li> <li class=md-nav__item> <a href=../plotting/ class=md-nav__link> <span class=md-ellipsis> Plotting </span> </a> </li> <li class=md-nav__item> <a href=../utils/ class=md-nav__link> <span class=md-ellipsis> Utilities </span> </a> </li> <li class=md-nav__item> <a href=../estimators/ class=md-nav__link> <span class=md-ellipsis> Estimators </span> </a> </li> <li class=md-nav__item> <a href=../filtering/ class=md-nav__link> <span class=md-ellipsis> Filtering </span> </a> </li> <li class=md-nav__item> <a href=../preprocessing/ class=md-nav__link> <span class=md-ellipsis> Preprocessing </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> HMM Utils </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> HMM Utils </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#nelpy.hmmutils class=md-nav__link> <span class=md-ellipsis> hmmutils </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM class=md-nav__link> <span class=md-ellipsis> PoissonHMM </span> </a> <nav class=md-nav aria-label=PoissonHMM> <ul class=md-nav__list> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.extern_ class=md-nav__link> <span class=md-ellipsis> extern_ </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.means class=md-nav__link> <span class=md-ellipsis> means </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.startprob class=md-nav__link> <span class=md-ellipsis> startprob </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.transmat class=md-nav__link> <span class=md-ellipsis> transmat </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.unit_ids class=md-nav__link> <span class=md-ellipsis> unit_ids </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.unit_labels class=md-nav__link> <span class=md-ellipsis> unit_labels </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.assume_attributes class=md-nav__link> <span class=md-ellipsis> assume_attributes </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.decode class=md-nav__link> <span class=md-ellipsis> decode </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.decode_ext class=md-nav__link> <span class=md-ellipsis> decode_ext </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.estimate_model_quality class=md-nav__link> <span class=md-ellipsis> estimate_model_quality </span> </a> <nav class=md-nav aria-label=estimate_model_quality> <ul class=md-nav__list> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.estimate_model_quality--params class=md-nav__link> <span class=md-ellipsis> Params </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.estimate_model_quality--returns class=md-nav__link> <span class=md-ellipsis> Returns </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.fit class=md-nav__link> <span class=md-ellipsis> fit </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.fit_ext class=md-nav__link> <span class=md-ellipsis> fit_ext </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.fit_ext2 class=md-nav__link> <span class=md-ellipsis> fit_ext2 </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.get_state_order class=md-nav__link> <span class=md-ellipsis> get_state_order </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.predict class=md-nav__link> <span class=md-ellipsis> predict </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.predict_proba class=md-nav__link> <span class=md-ellipsis> predict_proba </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.reorder_states class=md-nav__link> <span class=md-ellipsis> reorder_states </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.sample class=md-nav__link> <span class=md-ellipsis> sample </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.score class=md-nav__link> <span class=md-ellipsis> score </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.score_samples class=md-nav__link> <span class=md-ellipsis> score_samples </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.estimate_model_quality class=md-nav__link> <span class=md-ellipsis> estimate_model_quality </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tutorials/GettingStarted/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/AnalogSignalArrayTutorial/ class=md-nav__link> <span class=md-ellipsis> AnalogSignalArray Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/EpochArrayTutorial/ class=md-nav__link> <span class=md-ellipsis> EpochArray Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/LinearTrackDemo/ class=md-nav__link> <span class=md-ellipsis> Linear Track Demo </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/SpikeTrainSmoothing/ class=md-nav__link> <span class=md-ellipsis> SpikeTrain Smoothing </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/plotting/ class=md-nav__link> <span class=md-ellipsis> plotting </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/WMazeDemo/ class=md-nav__link> <span class=md-ellipsis> WMaze Demo </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/BackyardBrainsEEG/ class=md-nav__link> <span class=md-ellipsis> Backyard Brains EEG </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/develop/ class=md-nav__link> <span class=md-ellipsis> develop </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#nelpy.hmmutils class=md-nav__link> <span class=md-ellipsis> hmmutils </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM class=md-nav__link> <span class=md-ellipsis> PoissonHMM </span> </a> <nav class=md-nav aria-label=PoissonHMM> <ul class=md-nav__list> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.extern_ class=md-nav__link> <span class=md-ellipsis> extern_ </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.means class=md-nav__link> <span class=md-ellipsis> means </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.startprob class=md-nav__link> <span class=md-ellipsis> startprob </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.transmat class=md-nav__link> <span class=md-ellipsis> transmat </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.unit_ids class=md-nav__link> <span class=md-ellipsis> unit_ids </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.unit_labels class=md-nav__link> <span class=md-ellipsis> unit_labels </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.assume_attributes class=md-nav__link> <span class=md-ellipsis> assume_attributes </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.decode class=md-nav__link> <span class=md-ellipsis> decode </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.decode_ext class=md-nav__link> <span class=md-ellipsis> decode_ext </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.estimate_model_quality class=md-nav__link> <span class=md-ellipsis> estimate_model_quality </span> </a> <nav class=md-nav aria-label=estimate_model_quality> <ul class=md-nav__list> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.estimate_model_quality--params class=md-nav__link> <span class=md-ellipsis> Params </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.estimate_model_quality--returns class=md-nav__link> <span class=md-ellipsis> Returns </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.fit class=md-nav__link> <span class=md-ellipsis> fit </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.fit_ext class=md-nav__link> <span class=md-ellipsis> fit_ext </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.fit_ext2 class=md-nav__link> <span class=md-ellipsis> fit_ext2 </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.get_state_order class=md-nav__link> <span class=md-ellipsis> get_state_order </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.predict class=md-nav__link> <span class=md-ellipsis> predict </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.predict_proba class=md-nav__link> <span class=md-ellipsis> predict_proba </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.reorder_states class=md-nav__link> <span class=md-ellipsis> reorder_states </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.sample class=md-nav__link> <span class=md-ellipsis> sample </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.score class=md-nav__link> <span class=md-ellipsis> score </span> </a> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.PoissonHMM.score_samples class=md-nav__link> <span class=md-ellipsis> score_samples </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#nelpy.hmmutils.estimate_model_quality class=md-nav__link> <span class=md-ellipsis> estimate_model_quality </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/nelpy/nelpy/edit/master/docs/reference/hmmutils.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/nelpy/nelpy/raw/master/docs/reference/hmmutils.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=hmm-utils-api-reference>HMM Utils API Reference</h1> <div class="doc doc-object doc-module"> <a id=nelpy.hmmutils></a> <div class="doc doc-contents first"> <p>nelpy.hmmutils contains helper functions and wrappers for working with hmmlearn.</p> <div class="doc doc-children"> <div class="doc doc-object doc-class"> <h2 id=nelpy.hmmutils.PoissonHMM class="doc doc-heading"> <code>PoissonHMM</code> </h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=hmmlearn.hmm.PoissonHMM>PoissonHMM</span></code></p> <p>Nelpy extension of PoissonHMM: Hidden Markov Model with independent Poisson emissions.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>n_components</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of states.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>startprob_prior</code> </td> <td> <code>(<span title=array>array</span>, <span title=shape>shape</span>(<span title=n_components>n_components</span>))</code> </td> <td> <div class=doc-md-description> <p>Initial state occupation prior distribution.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>transmat_prior</code> </td> <td> <code>(<span title=array>array</span>, <span title=shape>shape</span>(<span title=n_components>n_components</span>, <span title=n_components>n_components</span>))</code> </td> <td> <div class=doc-md-description> <p>Matrix of prior transition probabilities between states.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>algorithm</code> </td> <td> <code>string, one of the :data:`base.DECODER_ALGORITHMS`</code> </td> <td> <div class=doc-md-description> <p>Decoder algorithm.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>random_state</code> </td> <td> </td> <td> <div class=doc-md-description> <p>A random number generator instance.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>n_iter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Maximum number of iterations to perform.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>tol</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Convergence threshold. EM will stop if the gain in log-likelihood is below this value.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>verbose</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>When <code>True</code> per-iteration convergence reports are printed to :data:<code>sys.stderr</code>. You can diagnose convergence via the :attr:<code>monitor_</code> attribute.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>params</code> </td> <td> <code><span title=string>string</span></code> </td> <td> <div class=doc-md-description> <p>Controls which parameters are updated in the training process. Can contain any combination of 's' for startprob, 't' for transmat, 'm' for means and 'c' for covars. Defaults to all parameters.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>init_params</code> </td> <td> <code><span title=string>string</span></code> </td> <td> <div class=doc-md-description> <p>Controls which parameters are initialized prior to training. Can contain any combination of 's' for startprob, 't' for transmat, 'm' for means and 'c' for covars. Defaults to all parameters.</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=nelpy.hmmutils.PoissonHMM.n_features>n_features</span></code></td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Dimensionality of the (independent) Poisson emissions.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=nelpy.hmmutils.PoissonHMM.monitor_>monitor_</span></code></td> <td> <code><span title=ConvergenceMonitor>ConvergenceMonitor</span></code> </td> <td> <div class=doc-md-description> <p>Monitor object used to check the convergence of EM.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=nelpy.hmmutils.PoissonHMM.transmat_>transmat_</span></code></td> <td> <code>(<span title=array>array</span>, <span title=shape>shape</span>(<span title=n_components>n_components</span>, <span title=n_components>n_components</span>))</code> </td> <td> <div class=doc-md-description> <p>Matrix of transition probabilities between states.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=nelpy.hmmutils.PoissonHMM.startprob_>startprob_</span></code></td> <td> <code>(<span title=array>array</span>, <span title=shape>shape</span>(<span title=n_components>n_components</span>))</code> </td> <td> <div class=doc-md-description> <p>Initial state occupation distribution.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=nelpy.hmmutils.PoissonHMM.means_>means_</span></code></td> <td> <code>(<span title=array>array</span>, <span title=shape>shape</span>(<span title=n_components>n_components</span>, <span title=n_features>n_features</span>))</code> </td> <td> <div class=doc-md-description> <p>Mean parameters for each state.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" href=#nelpy.hmmutils.PoissonHMM.extern_>extern_</a></code></td> <td> <code>(<span title=array>array</span>, <span title=shape>shape</span>(<span title=n_components>n_components</span>, <span title=n_extern>n_extern</span>))</code> </td> <td> <div class=doc-md-description> <p>Augmented mapping from state space to external variables.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=kn>from</span><span class=w> </span><span class=nn>nelpy.hmmutils</span><span class=w> </span><span class=kn>import</span> <span class=n>PoissonHMM</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>PoissonHMM</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span><span class=o>...</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 126</span>
<span class=normal> 127</span>
<span class=normal> 128</span>
<span class=normal> 129</span>
<span class=normal> 130</span>
<span class=normal> 131</span>
<span class=normal> 132</span>
<span class=normal> 133</span>
<span class=normal> 134</span>
<span class=normal> 135</span>
<span class=normal> 136</span>
<span class=normal> 137</span>
<span class=normal> 138</span>
<span class=normal> 139</span>
<span class=normal> 140</span>
<span class=normal> 141</span>
<span class=normal> 142</span>
<span class=normal> 143</span>
<span class=normal> 144</span>
<span class=normal> 145</span>
<span class=normal> 146</span>
<span class=normal> 147</span>
<span class=normal> 148</span>
<span class=normal> 149</span>
<span class=normal> 150</span>
<span class=normal> 151</span>
<span class=normal> 152</span>
<span class=normal> 153</span>
<span class=normal> 154</span>
<span class=normal> 155</span>
<span class=normal> 156</span>
<span class=normal> 157</span>
<span class=normal> 158</span>
<span class=normal> 159</span>
<span class=normal> 160</span>
<span class=normal> 161</span>
<span class=normal> 162</span>
<span class=normal> 163</span>
<span class=normal> 164</span>
<span class=normal> 165</span>
<span class=normal> 166</span>
<span class=normal> 167</span>
<span class=normal> 168</span>
<span class=normal> 169</span>
<span class=normal> 170</span>
<span class=normal> 171</span>
<span class=normal> 172</span>
<span class=normal> 173</span>
<span class=normal> 174</span>
<span class=normal> 175</span>
<span class=normal> 176</span>
<span class=normal> 177</span>
<span class=normal> 178</span>
<span class=normal> 179</span>
<span class=normal> 180</span>
<span class=normal> 181</span>
<span class=normal> 182</span>
<span class=normal> 183</span>
<span class=normal> 184</span>
<span class=normal> 185</span>
<span class=normal> 186</span>
<span class=normal> 187</span>
<span class=normal> 188</span>
<span class=normal> 189</span>
<span class=normal> 190</span>
<span class=normal> 191</span>
<span class=normal> 192</span>
<span class=normal> 193</span>
<span class=normal> 194</span>
<span class=normal> 195</span>
<span class=normal> 196</span>
<span class=normal> 197</span>
<span class=normal> 198</span>
<span class=normal> 199</span>
<span class=normal> 200</span>
<span class=normal> 201</span>
<span class=normal> 202</span>
<span class=normal> 203</span>
<span class=normal> 204</span>
<span class=normal> 205</span>
<span class=normal> 206</span>
<span class=normal> 207</span>
<span class=normal> 208</span>
<span class=normal> 209</span>
<span class=normal> 210</span>
<span class=normal> 211</span>
<span class=normal> 212</span>
<span class=normal> 213</span>
<span class=normal> 214</span>
<span class=normal> 215</span>
<span class=normal> 216</span>
<span class=normal> 217</span>
<span class=normal> 218</span>
<span class=normal> 219</span>
<span class=normal> 220</span>
<span class=normal> 221</span>
<span class=normal> 222</span>
<span class=normal> 223</span>
<span class=normal> 224</span>
<span class=normal> 225</span>
<span class=normal> 226</span>
<span class=normal> 227</span>
<span class=normal> 228</span>
<span class=normal> 229</span>
<span class=normal> 230</span>
<span class=normal> 231</span>
<span class=normal> 232</span>
<span class=normal> 233</span>
<span class=normal> 234</span>
<span class=normal> 235</span>
<span class=normal> 236</span>
<span class=normal> 237</span>
<span class=normal> 238</span>
<span class=normal> 239</span>
<span class=normal> 240</span>
<span class=normal> 241</span>
<span class=normal> 242</span>
<span class=normal> 243</span>
<span class=normal> 244</span>
<span class=normal> 245</span>
<span class=normal> 246</span>
<span class=normal> 247</span>
<span class=normal> 248</span>
<span class=normal> 249</span>
<span class=normal> 250</span>
<span class=normal> 251</span>
<span class=normal> 252</span>
<span class=normal> 253</span>
<span class=normal> 254</span>
<span class=normal> 255</span>
<span class=normal> 256</span>
<span class=normal> 257</span>
<span class=normal> 258</span>
<span class=normal> 259</span>
<span class=normal> 260</span>
<span class=normal> 261</span>
<span class=normal> 262</span>
<span class=normal> 263</span>
<span class=normal> 264</span>
<span class=normal> 265</span>
<span class=normal> 266</span>
<span class=normal> 267</span>
<span class=normal> 268</span>
<span class=normal> 269</span>
<span class=normal> 270</span>
<span class=normal> 271</span>
<span class=normal> 272</span>
<span class=normal> 273</span>
<span class=normal> 274</span>
<span class=normal> 275</span>
<span class=normal> 276</span>
<span class=normal> 277</span>
<span class=normal> 278</span>
<span class=normal> 279</span>
<span class=normal> 280</span>
<span class=normal> 281</span>
<span class=normal> 282</span>
<span class=normal> 283</span>
<span class=normal> 284</span>
<span class=normal> 285</span>
<span class=normal> 286</span>
<span class=normal> 287</span>
<span class=normal> 288</span>
<span class=normal> 289</span>
<span class=normal> 290</span>
<span class=normal> 291</span>
<span class=normal> 292</span>
<span class=normal> 293</span>
<span class=normal> 294</span>
<span class=normal> 295</span>
<span class=normal> 296</span>
<span class=normal> 297</span>
<span class=normal> 298</span>
<span class=normal> 299</span>
<span class=normal> 300</span>
<span class=normal> 301</span>
<span class=normal> 302</span>
<span class=normal> 303</span>
<span class=normal> 304</span>
<span class=normal> 305</span>
<span class=normal> 306</span>
<span class=normal> 307</span>
<span class=normal> 308</span>
<span class=normal> 309</span>
<span class=normal> 310</span>
<span class=normal> 311</span>
<span class=normal> 312</span>
<span class=normal> 313</span>
<span class=normal> 314</span>
<span class=normal> 315</span>
<span class=normal> 316</span>
<span class=normal> 317</span>
<span class=normal> 318</span>
<span class=normal> 319</span>
<span class=normal> 320</span>
<span class=normal> 321</span>
<span class=normal> 322</span>
<span class=normal> 323</span>
<span class=normal> 324</span>
<span class=normal> 325</span>
<span class=normal> 326</span>
<span class=normal> 327</span>
<span class=normal> 328</span>
<span class=normal> 329</span>
<span class=normal> 330</span>
<span class=normal> 331</span>
<span class=normal> 332</span>
<span class=normal> 333</span>
<span class=normal> 334</span>
<span class=normal> 335</span>
<span class=normal> 336</span>
<span class=normal> 337</span>
<span class=normal> 338</span>
<span class=normal> 339</span>
<span class=normal> 340</span>
<span class=normal> 341</span>
<span class=normal> 342</span>
<span class=normal> 343</span>
<span class=normal> 344</span>
<span class=normal> 345</span>
<span class=normal> 346</span>
<span class=normal> 347</span>
<span class=normal> 348</span>
<span class=normal> 349</span>
<span class=normal> 350</span>
<span class=normal> 351</span>
<span class=normal> 352</span>
<span class=normal> 353</span>
<span class=normal> 354</span>
<span class=normal> 355</span>
<span class=normal> 356</span>
<span class=normal> 357</span>
<span class=normal> 358</span>
<span class=normal> 359</span>
<span class=normal> 360</span>
<span class=normal> 361</span>
<span class=normal> 362</span>
<span class=normal> 363</span>
<span class=normal> 364</span>
<span class=normal> 365</span>
<span class=normal> 366</span>
<span class=normal> 367</span>
<span class=normal> 368</span>
<span class=normal> 369</span>
<span class=normal> 370</span>
<span class=normal> 371</span>
<span class=normal> 372</span>
<span class=normal> 373</span>
<span class=normal> 374</span>
<span class=normal> 375</span>
<span class=normal> 376</span>
<span class=normal> 377</span>
<span class=normal> 378</span>
<span class=normal> 379</span>
<span class=normal> 380</span>
<span class=normal> 381</span>
<span class=normal> 382</span>
<span class=normal> 383</span>
<span class=normal> 384</span>
<span class=normal> 385</span>
<span class=normal> 386</span>
<span class=normal> 387</span>
<span class=normal> 388</span>
<span class=normal> 389</span>
<span class=normal> 390</span>
<span class=normal> 391</span>
<span class=normal> 392</span>
<span class=normal> 393</span>
<span class=normal> 394</span>
<span class=normal> 395</span>
<span class=normal> 396</span>
<span class=normal> 397</span>
<span class=normal> 398</span>
<span class=normal> 399</span>
<span class=normal> 400</span>
<span class=normal> 401</span>
<span class=normal> 402</span>
<span class=normal> 403</span>
<span class=normal> 404</span>
<span class=normal> 405</span>
<span class=normal> 406</span>
<span class=normal> 407</span>
<span class=normal> 408</span>
<span class=normal> 409</span>
<span class=normal> 410</span>
<span class=normal> 411</span>
<span class=normal> 412</span>
<span class=normal> 413</span>
<span class=normal> 414</span>
<span class=normal> 415</span>
<span class=normal> 416</span>
<span class=normal> 417</span>
<span class=normal> 418</span>
<span class=normal> 419</span>
<span class=normal> 420</span>
<span class=normal> 421</span>
<span class=normal> 422</span>
<span class=normal> 423</span>
<span class=normal> 424</span>
<span class=normal> 425</span>
<span class=normal> 426</span>
<span class=normal> 427</span>
<span class=normal> 428</span>
<span class=normal> 429</span>
<span class=normal> 430</span>
<span class=normal> 431</span>
<span class=normal> 432</span>
<span class=normal> 433</span>
<span class=normal> 434</span>
<span class=normal> 435</span>
<span class=normal> 436</span>
<span class=normal> 437</span>
<span class=normal> 438</span>
<span class=normal> 439</span>
<span class=normal> 440</span>
<span class=normal> 441</span>
<span class=normal> 442</span>
<span class=normal> 443</span>
<span class=normal> 444</span>
<span class=normal> 445</span>
<span class=normal> 446</span>
<span class=normal> 447</span>
<span class=normal> 448</span>
<span class=normal> 449</span>
<span class=normal> 450</span>
<span class=normal> 451</span>
<span class=normal> 452</span>
<span class=normal> 453</span>
<span class=normal> 454</span>
<span class=normal> 455</span>
<span class=normal> 456</span>
<span class=normal> 457</span>
<span class=normal> 458</span>
<span class=normal> 459</span>
<span class=normal> 460</span>
<span class=normal> 461</span>
<span class=normal> 462</span>
<span class=normal> 463</span>
<span class=normal> 464</span>
<span class=normal> 465</span>
<span class=normal> 466</span>
<span class=normal> 467</span>
<span class=normal> 468</span>
<span class=normal> 469</span>
<span class=normal> 470</span>
<span class=normal> 471</span>
<span class=normal> 472</span>
<span class=normal> 473</span>
<span class=normal> 474</span>
<span class=normal> 475</span>
<span class=normal> 476</span>
<span class=normal> 477</span>
<span class=normal> 478</span>
<span class=normal> 479</span>
<span class=normal> 480</span>
<span class=normal> 481</span>
<span class=normal> 482</span>
<span class=normal> 483</span>
<span class=normal> 484</span>
<span class=normal> 485</span>
<span class=normal> 486</span>
<span class=normal> 487</span>
<span class=normal> 488</span>
<span class=normal> 489</span>
<span class=normal> 490</span>
<span class=normal> 491</span>
<span class=normal> 492</span>
<span class=normal> 493</span>
<span class=normal> 494</span>
<span class=normal> 495</span>
<span class=normal> 496</span>
<span class=normal> 497</span>
<span class=normal> 498</span>
<span class=normal> 499</span>
<span class=normal> 500</span>
<span class=normal> 501</span>
<span class=normal> 502</span>
<span class=normal> 503</span>
<span class=normal> 504</span>
<span class=normal> 505</span>
<span class=normal> 506</span>
<span class=normal> 507</span>
<span class=normal> 508</span>
<span class=normal> 509</span>
<span class=normal> 510</span>
<span class=normal> 511</span>
<span class=normal> 512</span>
<span class=normal> 513</span>
<span class=normal> 514</span>
<span class=normal> 515</span>
<span class=normal> 516</span>
<span class=normal> 517</span>
<span class=normal> 518</span>
<span class=normal> 519</span>
<span class=normal> 520</span>
<span class=normal> 521</span>
<span class=normal> 522</span>
<span class=normal> 523</span>
<span class=normal> 524</span>
<span class=normal> 525</span>
<span class=normal> 526</span>
<span class=normal> 527</span>
<span class=normal> 528</span>
<span class=normal> 529</span>
<span class=normal> 530</span>
<span class=normal> 531</span>
<span class=normal> 532</span>
<span class=normal> 533</span>
<span class=normal> 534</span>
<span class=normal> 535</span>
<span class=normal> 536</span>
<span class=normal> 537</span>
<span class=normal> 538</span>
<span class=normal> 539</span>
<span class=normal> 540</span>
<span class=normal> 541</span>
<span class=normal> 542</span>
<span class=normal> 543</span>
<span class=normal> 544</span>
<span class=normal> 545</span>
<span class=normal> 546</span>
<span class=normal> 547</span>
<span class=normal> 548</span>
<span class=normal> 549</span>
<span class=normal> 550</span>
<span class=normal> 551</span>
<span class=normal> 552</span>
<span class=normal> 553</span>
<span class=normal> 554</span>
<span class=normal> 555</span>
<span class=normal> 556</span>
<span class=normal> 557</span>
<span class=normal> 558</span>
<span class=normal> 559</span>
<span class=normal> 560</span>
<span class=normal> 561</span>
<span class=normal> 562</span>
<span class=normal> 563</span>
<span class=normal> 564</span>
<span class=normal> 565</span>
<span class=normal> 566</span>
<span class=normal> 567</span>
<span class=normal> 568</span>
<span class=normal> 569</span>
<span class=normal> 570</span>
<span class=normal> 571</span>
<span class=normal> 572</span>
<span class=normal> 573</span>
<span class=normal> 574</span>
<span class=normal> 575</span>
<span class=normal> 576</span>
<span class=normal> 577</span>
<span class=normal> 578</span>
<span class=normal> 579</span>
<span class=normal> 580</span>
<span class=normal> 581</span>
<span class=normal> 582</span>
<span class=normal> 583</span>
<span class=normal> 584</span>
<span class=normal> 585</span>
<span class=normal> 586</span>
<span class=normal> 587</span>
<span class=normal> 588</span>
<span class=normal> 589</span>
<span class=normal> 590</span>
<span class=normal> 591</span>
<span class=normal> 592</span>
<span class=normal> 593</span>
<span class=normal> 594</span>
<span class=normal> 595</span>
<span class=normal> 596</span>
<span class=normal> 597</span>
<span class=normal> 598</span>
<span class=normal> 599</span>
<span class=normal> 600</span>
<span class=normal> 601</span>
<span class=normal> 602</span>
<span class=normal> 603</span>
<span class=normal> 604</span>
<span class=normal> 605</span>
<span class=normal> 606</span>
<span class=normal> 607</span>
<span class=normal> 608</span>
<span class=normal> 609</span>
<span class=normal> 610</span>
<span class=normal> 611</span>
<span class=normal> 612</span>
<span class=normal> 613</span>
<span class=normal> 614</span>
<span class=normal> 615</span>
<span class=normal> 616</span>
<span class=normal> 617</span>
<span class=normal> 618</span>
<span class=normal> 619</span>
<span class=normal> 620</span>
<span class=normal> 621</span>
<span class=normal> 622</span>
<span class=normal> 623</span>
<span class=normal> 624</span>
<span class=normal> 625</span>
<span class=normal> 626</span>
<span class=normal> 627</span>
<span class=normal> 628</span>
<span class=normal> 629</span>
<span class=normal> 630</span>
<span class=normal> 631</span>
<span class=normal> 632</span>
<span class=normal> 633</span>
<span class=normal> 634</span>
<span class=normal> 635</span>
<span class=normal> 636</span>
<span class=normal> 637</span>
<span class=normal> 638</span>
<span class=normal> 639</span>
<span class=normal> 640</span>
<span class=normal> 641</span>
<span class=normal> 642</span>
<span class=normal> 643</span>
<span class=normal> 644</span>
<span class=normal> 645</span>
<span class=normal> 646</span>
<span class=normal> 647</span>
<span class=normal> 648</span>
<span class=normal> 649</span>
<span class=normal> 650</span>
<span class=normal> 651</span>
<span class=normal> 652</span>
<span class=normal> 653</span>
<span class=normal> 654</span>
<span class=normal> 655</span>
<span class=normal> 656</span>
<span class=normal> 657</span>
<span class=normal> 658</span>
<span class=normal> 659</span>
<span class=normal> 660</span>
<span class=normal> 661</span>
<span class=normal> 662</span>
<span class=normal> 663</span>
<span class=normal> 664</span>
<span class=normal> 665</span>
<span class=normal> 666</span>
<span class=normal> 667</span>
<span class=normal> 668</span>
<span class=normal> 669</span>
<span class=normal> 670</span>
<span class=normal> 671</span>
<span class=normal> 672</span>
<span class=normal> 673</span>
<span class=normal> 674</span>
<span class=normal> 675</span>
<span class=normal> 676</span>
<span class=normal> 677</span>
<span class=normal> 678</span>
<span class=normal> 679</span>
<span class=normal> 680</span>
<span class=normal> 681</span>
<span class=normal> 682</span>
<span class=normal> 683</span>
<span class=normal> 684</span>
<span class=normal> 685</span>
<span class=normal> 686</span>
<span class=normal> 687</span>
<span class=normal> 688</span>
<span class=normal> 689</span>
<span class=normal> 690</span>
<span class=normal> 691</span>
<span class=normal> 692</span>
<span class=normal> 693</span>
<span class=normal> 694</span>
<span class=normal> 695</span>
<span class=normal> 696</span>
<span class=normal> 697</span>
<span class=normal> 698</span>
<span class=normal> 699</span>
<span class=normal> 700</span>
<span class=normal> 701</span>
<span class=normal> 702</span>
<span class=normal> 703</span>
<span class=normal> 704</span>
<span class=normal> 705</span>
<span class=normal> 706</span>
<span class=normal> 707</span>
<span class=normal> 708</span>
<span class=normal> 709</span>
<span class=normal> 710</span>
<span class=normal> 711</span>
<span class=normal> 712</span>
<span class=normal> 713</span>
<span class=normal> 714</span>
<span class=normal> 715</span>
<span class=normal> 716</span>
<span class=normal> 717</span>
<span class=normal> 718</span>
<span class=normal> 719</span>
<span class=normal> 720</span>
<span class=normal> 721</span>
<span class=normal> 722</span>
<span class=normal> 723</span>
<span class=normal> 724</span>
<span class=normal> 725</span>
<span class=normal> 726</span>
<span class=normal> 727</span>
<span class=normal> 728</span>
<span class=normal> 729</span>
<span class=normal> 730</span>
<span class=normal> 731</span>
<span class=normal> 732</span>
<span class=normal> 733</span>
<span class=normal> 734</span>
<span class=normal> 735</span>
<span class=normal> 736</span>
<span class=normal> 737</span>
<span class=normal> 738</span>
<span class=normal> 739</span>
<span class=normal> 740</span>
<span class=normal> 741</span>
<span class=normal> 742</span>
<span class=normal> 743</span>
<span class=normal> 744</span>
<span class=normal> 745</span>
<span class=normal> 746</span>
<span class=normal> 747</span>
<span class=normal> 748</span>
<span class=normal> 749</span>
<span class=normal> 750</span>
<span class=normal> 751</span>
<span class=normal> 752</span>
<span class=normal> 753</span>
<span class=normal> 754</span>
<span class=normal> 755</span>
<span class=normal> 756</span>
<span class=normal> 757</span>
<span class=normal> 758</span>
<span class=normal> 759</span>
<span class=normal> 760</span>
<span class=normal> 761</span>
<span class=normal> 762</span>
<span class=normal> 763</span>
<span class=normal> 764</span>
<span class=normal> 765</span>
<span class=normal> 766</span>
<span class=normal> 767</span>
<span class=normal> 768</span>
<span class=normal> 769</span>
<span class=normal> 770</span>
<span class=normal> 771</span>
<span class=normal> 772</span>
<span class=normal> 773</span>
<span class=normal> 774</span>
<span class=normal> 775</span>
<span class=normal> 776</span>
<span class=normal> 777</span>
<span class=normal> 778</span>
<span class=normal> 779</span>
<span class=normal> 780</span>
<span class=normal> 781</span>
<span class=normal> 782</span>
<span class=normal> 783</span>
<span class=normal> 784</span>
<span class=normal> 785</span>
<span class=normal> 786</span>
<span class=normal> 787</span>
<span class=normal> 788</span>
<span class=normal> 789</span>
<span class=normal> 790</span>
<span class=normal> 791</span>
<span class=normal> 792</span>
<span class=normal> 793</span>
<span class=normal> 794</span>
<span class=normal> 795</span>
<span class=normal> 796</span>
<span class=normal> 797</span>
<span class=normal> 798</span>
<span class=normal> 799</span>
<span class=normal> 800</span>
<span class=normal> 801</span>
<span class=normal> 802</span>
<span class=normal> 803</span>
<span class=normal> 804</span>
<span class=normal> 805</span>
<span class=normal> 806</span>
<span class=normal> 807</span>
<span class=normal> 808</span>
<span class=normal> 809</span>
<span class=normal> 810</span>
<span class=normal> 811</span>
<span class=normal> 812</span>
<span class=normal> 813</span>
<span class=normal> 814</span>
<span class=normal> 815</span>
<span class=normal> 816</span>
<span class=normal> 817</span>
<span class=normal> 818</span>
<span class=normal> 819</span>
<span class=normal> 820</span>
<span class=normal> 821</span>
<span class=normal> 822</span>
<span class=normal> 823</span>
<span class=normal> 824</span>
<span class=normal> 825</span>
<span class=normal> 826</span>
<span class=normal> 827</span>
<span class=normal> 828</span>
<span class=normal> 829</span>
<span class=normal> 830</span>
<span class=normal> 831</span>
<span class=normal> 832</span>
<span class=normal> 833</span>
<span class=normal> 834</span>
<span class=normal> 835</span>
<span class=normal> 836</span>
<span class=normal> 837</span>
<span class=normal> 838</span>
<span class=normal> 839</span>
<span class=normal> 840</span>
<span class=normal> 841</span>
<span class=normal> 842</span>
<span class=normal> 843</span>
<span class=normal> 844</span>
<span class=normal> 845</span>
<span class=normal> 846</span>
<span class=normal> 847</span>
<span class=normal> 848</span>
<span class=normal> 849</span>
<span class=normal> 850</span>
<span class=normal> 851</span>
<span class=normal> 852</span>
<span class=normal> 853</span>
<span class=normal> 854</span>
<span class=normal> 855</span>
<span class=normal> 856</span>
<span class=normal> 857</span>
<span class=normal> 858</span>
<span class=normal> 859</span>
<span class=normal> 860</span>
<span class=normal> 861</span>
<span class=normal> 862</span>
<span class=normal> 863</span>
<span class=normal> 864</span>
<span class=normal> 865</span>
<span class=normal> 866</span>
<span class=normal> 867</span>
<span class=normal> 868</span>
<span class=normal> 869</span>
<span class=normal> 870</span>
<span class=normal> 871</span>
<span class=normal> 872</span>
<span class=normal> 873</span>
<span class=normal> 874</span>
<span class=normal> 875</span>
<span class=normal> 876</span>
<span class=normal> 877</span>
<span class=normal> 878</span>
<span class=normal> 879</span>
<span class=normal> 880</span>
<span class=normal> 881</span>
<span class=normal> 882</span>
<span class=normal> 883</span>
<span class=normal> 884</span>
<span class=normal> 885</span>
<span class=normal> 886</span>
<span class=normal> 887</span>
<span class=normal> 888</span>
<span class=normal> 889</span>
<span class=normal> 890</span>
<span class=normal> 891</span>
<span class=normal> 892</span>
<span class=normal> 893</span>
<span class=normal> 894</span>
<span class=normal> 895</span>
<span class=normal> 896</span>
<span class=normal> 897</span>
<span class=normal> 898</span>
<span class=normal> 899</span>
<span class=normal> 900</span>
<span class=normal> 901</span>
<span class=normal> 902</span>
<span class=normal> 903</span>
<span class=normal> 904</span>
<span class=normal> 905</span>
<span class=normal> 906</span>
<span class=normal> 907</span>
<span class=normal> 908</span>
<span class=normal> 909</span>
<span class=normal> 910</span>
<span class=normal> 911</span>
<span class=normal> 912</span>
<span class=normal> 913</span>
<span class=normal> 914</span>
<span class=normal> 915</span>
<span class=normal> 916</span>
<span class=normal> 917</span>
<span class=normal> 918</span>
<span class=normal> 919</span>
<span class=normal> 920</span>
<span class=normal> 921</span>
<span class=normal> 922</span>
<span class=normal> 923</span>
<span class=normal> 924</span>
<span class=normal> 925</span>
<span class=normal> 926</span>
<span class=normal> 927</span>
<span class=normal> 928</span>
<span class=normal> 929</span>
<span class=normal> 930</span>
<span class=normal> 931</span>
<span class=normal> 932</span>
<span class=normal> 933</span>
<span class=normal> 934</span>
<span class=normal> 935</span>
<span class=normal> 936</span>
<span class=normal> 937</span>
<span class=normal> 938</span>
<span class=normal> 939</span>
<span class=normal> 940</span>
<span class=normal> 941</span>
<span class=normal> 942</span>
<span class=normal> 943</span>
<span class=normal> 944</span>
<span class=normal> 945</span>
<span class=normal> 946</span>
<span class=normal> 947</span>
<span class=normal> 948</span>
<span class=normal> 949</span>
<span class=normal> 950</span>
<span class=normal> 951</span>
<span class=normal> 952</span>
<span class=normal> 953</span>
<span class=normal> 954</span>
<span class=normal> 955</span>
<span class=normal> 956</span>
<span class=normal> 957</span>
<span class=normal> 958</span>
<span class=normal> 959</span>
<span class=normal> 960</span>
<span class=normal> 961</span>
<span class=normal> 962</span>
<span class=normal> 963</span>
<span class=normal> 964</span>
<span class=normal> 965</span>
<span class=normal> 966</span>
<span class=normal> 967</span>
<span class=normal> 968</span>
<span class=normal> 969</span>
<span class=normal> 970</span>
<span class=normal> 971</span>
<span class=normal> 972</span>
<span class=normal> 973</span>
<span class=normal> 974</span>
<span class=normal> 975</span>
<span class=normal> 976</span>
<span class=normal> 977</span>
<span class=normal> 978</span>
<span class=normal> 979</span>
<span class=normal> 980</span>
<span class=normal> 981</span>
<span class=normal> 982</span>
<span class=normal> 983</span>
<span class=normal> 984</span>
<span class=normal> 985</span>
<span class=normal> 986</span>
<span class=normal> 987</span>
<span class=normal> 988</span>
<span class=normal> 989</span>
<span class=normal> 990</span>
<span class=normal> 991</span>
<span class=normal> 992</span>
<span class=normal> 993</span>
<span class=normal> 994</span>
<span class=normal> 995</span>
<span class=normal> 996</span>
<span class=normal> 997</span>
<span class=normal> 998</span>
<span class=normal> 999</span>
<span class=normal>1000</span>
<span class=normal>1001</span>
<span class=normal>1002</span>
<span class=normal>1003</span>
<span class=normal>1004</span>
<span class=normal>1005</span>
<span class=normal>1006</span>
<span class=normal>1007</span>
<span class=normal>1008</span>
<span class=normal>1009</span>
<span class=normal>1010</span>
<span class=normal>1011</span>
<span class=normal>1012</span>
<span class=normal>1013</span>
<span class=normal>1014</span>
<span class=normal>1015</span>
<span class=normal>1016</span>
<span class=normal>1017</span>
<span class=normal>1018</span>
<span class=normal>1019</span>
<span class=normal>1020</span>
<span class=normal>1021</span>
<span class=normal>1022</span>
<span class=normal>1023</span>
<span class=normal>1024</span>
<span class=normal>1025</span>
<span class=normal>1026</span>
<span class=normal>1027</span>
<span class=normal>1028</span>
<span class=normal>1029</span>
<span class=normal>1030</span>
<span class=normal>1031</span>
<span class=normal>1032</span>
<span class=normal>1033</span>
<span class=normal>1034</span>
<span class=normal>1035</span>
<span class=normal>1036</span>
<span class=normal>1037</span>
<span class=normal>1038</span>
<span class=normal>1039</span>
<span class=normal>1040</span>
<span class=normal>1041</span>
<span class=normal>1042</span>
<span class=normal>1043</span>
<span class=normal>1044</span>
<span class=normal>1045</span>
<span class=normal>1046</span>
<span class=normal>1047</span>
<span class=normal>1048</span>
<span class=normal>1049</span>
<span class=normal>1050</span>
<span class=normal>1051</span>
<span class=normal>1052</span>
<span class=normal>1053</span>
<span class=normal>1054</span>
<span class=normal>1055</span>
<span class=normal>1056</span>
<span class=normal>1057</span>
<span class=normal>1058</span>
<span class=normal>1059</span>
<span class=normal>1060</span>
<span class=normal>1061</span>
<span class=normal>1062</span>
<span class=normal>1063</span>
<span class=normal>1064</span>
<span class=normal>1065</span>
<span class=normal>1066</span>
<span class=normal>1067</span>
<span class=normal>1068</span>
<span class=normal>1069</span>
<span class=normal>1070</span>
<span class=normal>1071</span>
<span class=normal>1072</span>
<span class=normal>1073</span>
<span class=normal>1074</span>
<span class=normal>1075</span>
<span class=normal>1076</span>
<span class=normal>1077</span>
<span class=normal>1078</span>
<span class=normal>1079</span>
<span class=normal>1080</span>
<span class=normal>1081</span>
<span class=normal>1082</span>
<span class=normal>1083</span>
<span class=normal>1084</span>
<span class=normal>1085</span>
<span class=normal>1086</span>
<span class=normal>1087</span>
<span class=normal>1088</span>
<span class=normal>1089</span>
<span class=normal>1090</span>
<span class=normal>1091</span>
<span class=normal>1092</span>
<span class=normal>1093</span>
<span class=normal>1094</span>
<span class=normal>1095</span>
<span class=normal>1096</span>
<span class=normal>1097</span>
<span class=normal>1098</span>
<span class=normal>1099</span>
<span class=normal>1100</span>
<span class=normal>1101</span>
<span class=normal>1102</span>
<span class=normal>1103</span>
<span class=normal>1104</span>
<span class=normal>1105</span>
<span class=normal>1106</span>
<span class=normal>1107</span>
<span class=normal>1108</span>
<span class=normal>1109</span>
<span class=normal>1110</span>
<span class=normal>1111</span>
<span class=normal>1112</span>
<span class=normal>1113</span>
<span class=normal>1114</span>
<span class=normal>1115</span>
<span class=normal>1116</span>
<span class=normal>1117</span>
<span class=normal>1118</span>
<span class=normal>1119</span>
<span class=normal>1120</span>
<span class=normal>1121</span>
<span class=normal>1122</span>
<span class=normal>1123</span>
<span class=normal>1124</span>
<span class=normal>1125</span>
<span class=normal>1126</span>
<span class=normal>1127</span>
<span class=normal>1128</span>
<span class=normal>1129</span>
<span class=normal>1130</span>
<span class=normal>1131</span>
<span class=normal>1132</span>
<span class=normal>1133</span>
<span class=normal>1134</span>
<span class=normal>1135</span>
<span class=normal>1136</span>
<span class=normal>1137</span>
<span class=normal>1138</span>
<span class=normal>1139</span>
<span class=normal>1140</span>
<span class=normal>1141</span>
<span class=normal>1142</span>
<span class=normal>1143</span>
<span class=normal>1144</span>
<span class=normal>1145</span>
<span class=normal>1146</span>
<span class=normal>1147</span>
<span class=normal>1148</span>
<span class=normal>1149</span>
<span class=normal>1150</span>
<span class=normal>1151</span>
<span class=normal>1152</span>
<span class=normal>1153</span>
<span class=normal>1154</span>
<span class=normal>1155</span>
<span class=normal>1156</span>
<span class=normal>1157</span>
<span class=normal>1158</span>
<span class=normal>1159</span>
<span class=normal>1160</span>
<span class=normal>1161</span>
<span class=normal>1162</span>
<span class=normal>1163</span>
<span class=normal>1164</span>
<span class=normal>1165</span>
<span class=normal>1166</span>
<span class=normal>1167</span>
<span class=normal>1168</span>
<span class=normal>1169</span>
<span class=normal>1170</span>
<span class=normal>1171</span>
<span class=normal>1172</span>
<span class=normal>1173</span>
<span class=normal>1174</span>
<span class=normal>1175</span>
<span class=normal>1176</span>
<span class=normal>1177</span>
<span class=normal>1178</span>
<span class=normal>1179</span>
<span class=normal>1180</span>
<span class=normal>1181</span>
<span class=normal>1182</span>
<span class=normal>1183</span>
<span class=normal>1184</span>
<span class=normal>1185</span>
<span class=normal>1186</span>
<span class=normal>1187</span>
<span class=normal>1188</span>
<span class=normal>1189</span>
<span class=normal>1190</span>
<span class=normal>1191</span>
<span class=normal>1192</span>
<span class=normal>1193</span>
<span class=normal>1194</span>
<span class=normal>1195</span>
<span class=normal>1196</span>
<span class=normal>1197</span>
<span class=normal>1198</span>
<span class=normal>1199</span>
<span class=normal>1200</span>
<span class=normal>1201</span>
<span class=normal>1202</span>
<span class=normal>1203</span>
<span class=normal>1204</span>
<span class=normal>1205</span>
<span class=normal>1206</span>
<span class=normal>1207</span>
<span class=normal>1208</span>
<span class=normal>1209</span>
<span class=normal>1210</span>
<span class=normal>1211</span>
<span class=normal>1212</span>
<span class=normal>1213</span>
<span class=normal>1214</span>
<span class=normal>1215</span>
<span class=normal>1216</span>
<span class=normal>1217</span>
<span class=normal>1218</span>
<span class=normal>1219</span>
<span class=normal>1220</span>
<span class=normal>1221</span>
<span class=normal>1222</span>
<span class=normal>1223</span>
<span class=normal>1224</span>
<span class=normal>1225</span>
<span class=normal>1226</span>
<span class=normal>1227</span>
<span class=normal>1228</span>
<span class=normal>1229</span>
<span class=normal>1230</span>
<span class=normal>1231</span>
<span class=normal>1232</span>
<span class=normal>1233</span>
<span class=normal>1234</span>
<span class=normal>1235</span>
<span class=normal>1236</span>
<span class=normal>1237</span>
<span class=normal>1238</span>
<span class=normal>1239</span>
<span class=normal>1240</span>
<span class=normal>1241</span>
<span class=normal>1242</span>
<span class=normal>1243</span>
<span class=normal>1244</span>
<span class=normal>1245</span>
<span class=normal>1246</span>
<span class=normal>1247</span>
<span class=normal>1248</span>
<span class=normal>1249</span>
<span class=normal>1250</span>
<span class=normal>1251</span>
<span class=normal>1252</span>
<span class=normal>1253</span>
<span class=normal>1254</span>
<span class=normal>1255</span>
<span class=normal>1256</span>
<span class=normal>1257</span>
<span class=normal>1258</span>
<span class=normal>1259</span>
<span class=normal>1260</span>
<span class=normal>1261</span>
<span class=normal>1262</span>
<span class=normal>1263</span>
<span class=normal>1264</span>
<span class=normal>1265</span>
<span class=normal>1266</span>
<span class=normal>1267</span>
<span class=normal>1268</span>
<span class=normal>1269</span>
<span class=normal>1270</span>
<span class=normal>1271</span>
<span class=normal>1272</span>
<span class=normal>1273</span>
<span class=normal>1274</span>
<span class=normal>1275</span>
<span class=normal>1276</span>
<span class=normal>1277</span>
<span class=normal>1278</span>
<span class=normal>1279</span>
<span class=normal>1280</span>
<span class=normal>1281</span>
<span class=normal>1282</span>
<span class=normal>1283</span>
<span class=normal>1284</span>
<span class=normal>1285</span>
<span class=normal>1286</span>
<span class=normal>1287</span>
<span class=normal>1288</span>
<span class=normal>1289</span>
<span class=normal>1290</span>
<span class=normal>1291</span>
<span class=normal>1292</span>
<span class=normal>1293</span>
<span class=normal>1294</span>
<span class=normal>1295</span>
<span class=normal>1296</span>
<span class=normal>1297</span>
<span class=normal>1298</span>
<span class=normal>1299</span>
<span class=normal>1300</span>
<span class=normal>1301</span>
<span class=normal>1302</span>
<span class=normal>1303</span>
<span class=normal>1304</span>
<span class=normal>1305</span>
<span class=normal>1306</span>
<span class=normal>1307</span>
<span class=normal>1308</span>
<span class=normal>1309</span>
<span class=normal>1310</span>
<span class=normal>1311</span>
<span class=normal>1312</span>
<span class=normal>1313</span>
<span class=normal>1314</span>
<span class=normal>1315</span>
<span class=normal>1316</span>
<span class=normal>1317</span>
<span class=normal>1318</span>
<span class=normal>1319</span>
<span class=normal>1320</span>
<span class=normal>1321</span>
<span class=normal>1322</span>
<span class=normal>1323</span>
<span class=normal>1324</span>
<span class=normal>1325</span>
<span class=normal>1326</span>
<span class=normal>1327</span>
<span class=normal>1328</span>
<span class=normal>1329</span>
<span class=normal>1330</span>
<span class=normal>1331</span>
<span class=normal>1332</span>
<span class=normal>1333</span>
<span class=normal>1334</span>
<span class=normal>1335</span>
<span class=normal>1336</span>
<span class=normal>1337</span>
<span class=normal>1338</span>
<span class=normal>1339</span>
<span class=normal>1340</span>
<span class=normal>1341</span>
<span class=normal>1342</span>
<span class=normal>1343</span>
<span class=normal>1344</span>
<span class=normal>1345</span>
<span class=normal>1346</span>
<span class=normal>1347</span>
<span class=normal>1348</span>
<span class=normal>1349</span>
<span class=normal>1350</span>
<span class=normal>1351</span>
<span class=normal>1352</span>
<span class=normal>1353</span>
<span class=normal>1354</span>
<span class=normal>1355</span>
<span class=normal>1356</span>
<span class=normal>1357</span>
<span class=normal>1358</span>
<span class=normal>1359</span>
<span class=normal>1360</span>
<span class=normal>1361</span>
<span class=normal>1362</span>
<span class=normal>1363</span>
<span class=normal>1364</span>
<span class=normal>1365</span>
<span class=normal>1366</span>
<span class=normal>1367</span>
<span class=normal>1368</span>
<span class=normal>1369</span>
<span class=normal>1370</span>
<span class=normal>1371</span>
<span class=normal>1372</span>
<span class=normal>1373</span>
<span class=normal>1374</span>
<span class=normal>1375</span>
<span class=normal>1376</span>
<span class=normal>1377</span>
<span class=normal>1378</span>
<span class=normal>1379</span>
<span class=normal>1380</span>
<span class=normal>1381</span>
<span class=normal>1382</span>
<span class=normal>1383</span>
<span class=normal>1384</span>
<span class=normal>1385</span>
<span class=normal>1386</span>
<span class=normal>1387</span>
<span class=normal>1388</span>
<span class=normal>1389</span>
<span class=normal>1390</span>
<span class=normal>1391</span>
<span class=normal>1392</span>
<span class=normal>1393</span>
<span class=normal>1394</span>
<span class=normal>1395</span>
<span class=normal>1396</span>
<span class=normal>1397</span>
<span class=normal>1398</span>
<span class=normal>1399</span>
<span class=normal>1400</span>
<span class=normal>1401</span>
<span class=normal>1402</span>
<span class=normal>1403</span>
<span class=normal>1404</span>
<span class=normal>1405</span>
<span class=normal>1406</span>
<span class=normal>1407</span>
<span class=normal>1408</span>
<span class=normal>1409</span>
<span class=normal>1410</span>
<span class=normal>1411</span>
<span class=normal>1412</span>
<span class=normal>1413</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>PoissonHMM</span><span class=p>(</span><span class=n>PHMM</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Nelpy extension of PoissonHMM: Hidden Markov Model with</span>
<span class=sd>    independent Poisson emissions.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    n_components : int</span>
<span class=sd>        Number of states.</span>

<span class=sd>    startprob_prior : array, shape (n_components, )</span>
<span class=sd>        Initial state occupation prior distribution.</span>

<span class=sd>    transmat_prior : array, shape (n_components, n_components)</span>
<span class=sd>        Matrix of prior transition probabilities between states.</span>

<span class=sd>    algorithm : string, one of the :data:`base.DECODER_ALGORITHMS`</span>
<span class=sd>        Decoder algorithm.</span>

<span class=sd>    random_state: RandomState or an int seed (0 by default)</span>
<span class=sd>        A random number generator instance.</span>

<span class=sd>    n_iter : int, optional</span>
<span class=sd>        Maximum number of iterations to perform.</span>

<span class=sd>    tol : float, optional</span>
<span class=sd>        Convergence threshold. EM will stop if the gain in log-likelihood</span>
<span class=sd>        is below this value.</span>

<span class=sd>    verbose : bool, optional</span>
<span class=sd>        When ``True`` per-iteration convergence reports are printed</span>
<span class=sd>        to :data:`sys.stderr`. You can diagnose convergence via the</span>
<span class=sd>        :attr:`monitor_` attribute.</span>

<span class=sd>    params : string, optional</span>
<span class=sd>        Controls which parameters are updated in the training</span>
<span class=sd>        process.  Can contain any combination of &#39;s&#39; for startprob,</span>
<span class=sd>        &#39;t&#39; for transmat, &#39;m&#39; for means and &#39;c&#39; for covars. Defaults</span>
<span class=sd>        to all parameters.</span>

<span class=sd>    init_params : string, optional</span>
<span class=sd>        Controls which parameters are initialized prior to</span>
<span class=sd>        training.  Can contain any combination of &#39;s&#39; for</span>
<span class=sd>        startprob, &#39;t&#39; for transmat, &#39;m&#39; for means and &#39;c&#39; for covars.</span>
<span class=sd>        Defaults to all parameters.</span>

<span class=sd>    Attributes</span>
<span class=sd>    ----------</span>
<span class=sd>    n_features : int</span>
<span class=sd>        Dimensionality of the (independent) Poisson emissions.</span>

<span class=sd>    monitor_ : ConvergenceMonitor</span>
<span class=sd>        Monitor object used to check the convergence of EM.</span>

<span class=sd>    transmat_ : array, shape (n_components, n_components)</span>
<span class=sd>        Matrix of transition probabilities between states.</span>

<span class=sd>    startprob_ : array, shape (n_components, )</span>
<span class=sd>        Initial state occupation distribution.</span>

<span class=sd>    means_ : array, shape (n_components, n_features)</span>
<span class=sd>        Mean parameters for each state.</span>

<span class=sd>    extern_ : array, shape (n_components, n_extern)</span>
<span class=sd>        Augmented mapping from state space to external variables.</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    &gt;&gt;&gt; from nelpy.hmmutils import PoissonHMM</span>
<span class=sd>    &gt;&gt;&gt; PoissonHMM(n_components=2)...</span>

<span class=sd>    &quot;&quot;&quot;</span>

    <span class=n>__attributes__</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;_fs&quot;</span><span class=p>,</span> <span class=s2>&quot;_ds&quot;</span><span class=p>,</span> <span class=s2>&quot;_unit_ids&quot;</span><span class=p>,</span> <span class=s2>&quot;_unit_labels&quot;</span><span class=p>,</span> <span class=s2>&quot;_unit_tags&quot;</span><span class=p>]</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=o>*</span><span class=p>,</span>
        <span class=n>n_components</span><span class=p>,</span>
        <span class=n>n_iter</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>init_params</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>params</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
    <span class=p>):</span>
        <span class=c1># assign default parameter values</span>
        <span class=k>if</span> <span class=n>n_iter</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>n_iter</span> <span class=o>=</span> <span class=mi>50</span>
        <span class=k>if</span> <span class=n>init_params</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>init_params</span> <span class=o>=</span> <span class=s2>&quot;stm&quot;</span>
        <span class=k>if</span> <span class=n>params</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>params</span> <span class=o>=</span> <span class=s2>&quot;stm&quot;</span>

        <span class=c1># TODO: I don&#39;t understand why super().__init__ does not work?</span>
        <span class=n>PHMM</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span>
            <span class=bp>self</span><span class=p>,</span>
            <span class=n>n_components</span><span class=o>=</span><span class=n>n_components</span><span class=p>,</span>
            <span class=n>n_iter</span><span class=o>=</span><span class=n>n_iter</span><span class=p>,</span>
            <span class=n>init_params</span><span class=o>=</span><span class=n>init_params</span><span class=p>,</span>
            <span class=n>params</span><span class=o>=</span><span class=n>params</span><span class=p>,</span>
            <span class=n>random_state</span><span class=o>=</span><span class=n>random_state</span><span class=p>,</span>
            <span class=n>verbose</span><span class=o>=</span><span class=n>verbose</span><span class=p>,</span>
        <span class=p>)</span>

        <span class=c1># initialize BinnedSpikeTrain attributes</span>
        <span class=k>for</span> <span class=n>attrib</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>__attributes__</span><span class=p>:</span>
            <span class=n>exec</span><span class=p>(</span><span class=s2>&quot;self.&quot;</span> <span class=o>+</span> <span class=n>attrib</span> <span class=o>+</span> <span class=s2>&quot; = None&quot;</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_ds</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=c1># self._extern_map = None</span>

        <span class=c1># create shortcuts to super() methods that are overridden in</span>
        <span class=c1># this class</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_fit</span> <span class=o>=</span> <span class=n>PHMM</span><span class=o>.</span><span class=n>fit</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_score</span> <span class=o>=</span> <span class=n>PHMM</span><span class=o>.</span><span class=n>score</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_score_samples</span> <span class=o>=</span> <span class=n>PHMM</span><span class=o>.</span><span class=n>score_samples</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_predict</span> <span class=o>=</span> <span class=n>PHMM</span><span class=o>.</span><span class=n>predict</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span> <span class=o>=</span> <span class=n>PHMM</span><span class=o>.</span><span class=n>predict_proba</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_decode</span> <span class=o>=</span> <span class=n>PHMM</span><span class=o>.</span><span class=n>decode</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>_sample</span> <span class=o>=</span> <span class=n>PHMM</span><span class=o>.</span><span class=n>sample</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__repr__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=n>rep</span> <span class=o>=</span> <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__repr__</span><span class=p>()</span>
        <span class=k>except</span> <span class=ne>Exception</span><span class=p>:</span>
            <span class=n>warn</span><span class=p>(</span>
                <span class=s2>&quot;couldn&#39;t access super().__repr__;&quot;</span>
                <span class=s2>&quot; upgrade dependencies to resolve this issue.&quot;</span>
            <span class=p>)</span>
            <span class=n>rep</span> <span class=o>=</span> <span class=s2>&quot;PoissonHMM&quot;</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>fit_ext</span> <span class=o>=</span> <span class=s2>&quot;True&quot;</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>fit_ext</span> <span class=o>=</span> <span class=s2>&quot;False&quot;</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=n>fit</span> <span class=o>=</span> <span class=s2>&quot;False&quot;</span>
            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>means_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=n>fit</span> <span class=o>=</span> <span class=s2>&quot;True&quot;</span>
        <span class=k>except</span> <span class=ne>AttributeError</span><span class=p>:</span>
            <span class=n>fit</span> <span class=o>=</span> <span class=s2>&quot;False&quot;</span>
        <span class=n>fitstr</span> <span class=o>=</span> <span class=s2>&quot;; fit=&quot;</span> <span class=o>+</span> <span class=n>fit</span> <span class=o>+</span> <span class=s2>&quot;, fit_ext=&quot;</span> <span class=o>+</span> <span class=n>fit_ext</span>
        <span class=k>return</span> <span class=s2>&quot;nelpy.&quot;</span> <span class=o>+</span> <span class=n>rep</span> <span class=o>+</span> <span class=n>fitstr</span>

    <span class=nd>@property</span>
    <span class=k>def</span><span class=w> </span><span class=nf>extern_</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Mapping from states to external variables (e.g., position).</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        np.ndarray or None</span>
<span class=sd>            Array of shape (n_components, n_extern) containing the mapping</span>
<span class=sd>            from states to external variables. Returns None if no mapping</span>
<span class=sd>            has been learned yet.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; hmm.fit_ext(bst, position_data)</span>
<span class=sd>        &gt;&gt;&gt; extern_map = hmm.extern_</span>
<span class=sd>        &gt;&gt;&gt; print(f&quot;State 0 maps to position bin {np.argmax(extern_map[0])}&quot;)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>warn</span><span class=p>(</span><span class=s2>&quot;no state &lt;--&gt; external mapping has been learnt yet!&quot;</span><span class=p>)</span>
            <span class=k>return</span> <span class=kc>None</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_get_order_from_transmat</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>start_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Determine a state ordering based on the transition matrix.</span>

<span class=sd>        This is a greedy approach, starting at the a priori most probable</span>
<span class=sd>        state, and moving to the next most probable state according to</span>
<span class=sd>        the transition matrix, and so on.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        start_state : int, optional</span>
<span class=sd>            Initial state to begin from. Defaults to the most probable</span>
<span class=sd>            a priori state.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        new_order : list</span>
<span class=sd>            List of states in transmat order.</span>
<span class=sd>        &quot;&quot;&quot;</span>

        <span class=c1># unless specified, start in the a priori most probable state</span>
        <span class=k>if</span> <span class=n>start_state</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>start_state</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>)</span>

        <span class=n>new_order</span> <span class=o>=</span> <span class=p>[</span><span class=n>start_state</span><span class=p>]</span>
        <span class=n>num_states</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>transmat_</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>rem_states</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>start_state</span><span class=p>)</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
        <span class=n>rem_states</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>start_state</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>num_states</span><span class=p>)</span><span class=o>.</span><span class=n>tolist</span><span class=p>())</span>
        <span class=n>cs</span> <span class=o>=</span> <span class=n>start_state</span>  <span class=c1># current state</span>

        <span class=k>for</span> <span class=n>ii</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>num_states</span> <span class=o>-</span> <span class=mi>1</span><span class=p>):</span>
            <span class=c1># find largest transition to set of remaining states</span>
            <span class=n>nstilde</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>transmat_</span><span class=p>[</span><span class=n>cs</span><span class=p>,</span> <span class=n>rem_states</span><span class=p>])</span>
            <span class=n>ns</span> <span class=o>=</span> <span class=n>rem_states</span><span class=p>[</span><span class=n>nstilde</span><span class=p>]</span>
            <span class=c1># remove selected state from list of remaining states</span>
            <span class=n>rem_states</span><span class=o>.</span><span class=n>remove</span><span class=p>(</span><span class=n>ns</span><span class=p>)</span>
            <span class=n>cs</span> <span class=o>=</span> <span class=n>ns</span>
            <span class=n>new_order</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>cs</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>new_order</span>

    <span class=nd>@property</span>
    <span class=k>def</span><span class=w> </span><span class=nf>unit_ids</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        List of unit IDs associated with the model.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        list</span>
<span class=sd>            List of unit IDs.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_unit_ids</span>

    <span class=nd>@property</span>
    <span class=k>def</span><span class=w> </span><span class=nf>unit_labels</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        List of unit labels associated with the model.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        list</span>
<span class=sd>            List of unit labels.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_unit_labels</span>

    <span class=nd>@property</span>
    <span class=k>def</span><span class=w> </span><span class=nf>means</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Observation matrix (mean firing rates for each state and unit).</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        np.ndarray</span>
<span class=sd>            Array of shape (n_components, n_units) containing the mean parameters for each state.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>means_</span>

    <span class=nd>@property</span>
    <span class=k>def</span><span class=w> </span><span class=nf>transmat</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Transition probability matrix.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        np.ndarray</span>
<span class=sd>            Array of shape (n_components, n_components) where A[i, j] = Pr(S_{t+1}=j | S_t=i).</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>transmat_</span>

    <span class=nd>@property</span>
    <span class=k>def</span><span class=w> </span><span class=nf>startprob</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Prior distribution over states.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        np.ndarray</span>
<span class=sd>            Array of shape (n_components,) representing the initial state probabilities.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span>

    <span class=k>def</span><span class=w> </span><span class=nf>get_state_order</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>method</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>start_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Return a state ordering, optionally using augmented data.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        method : {&#39;transmat&#39;, &#39;mode&#39;, &#39;mean&#39;}, optional</span>
<span class=sd>            Method to use for ordering states. &#39;transmat&#39; (default) uses the transition matrix.</span>
<span class=sd>            &#39;mode&#39; or &#39;mean&#39; use the external mapping (requires self._extern_).</span>
<span class=sd>        start_state : int, optional</span>
<span class=sd>            Initial state to begin from (used only if method is &#39;transmat&#39;).</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        neworder : list</span>
<span class=sd>            List of state indices in the new order.</span>

<span class=sd>        Notes</span>
<span class=sd>        -----</span>
<span class=sd>        Both &#39;mode&#39; and &#39;mean&#39; assume that _extern_ is in sorted order; this is not verified explicitly.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; order = hmm.get_state_order(method=&quot;transmat&quot;)</span>
<span class=sd>        &gt;&gt;&gt; order = hmm.get_state_order(method=&quot;mode&quot;)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=n>method</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>method</span> <span class=o>=</span> <span class=s2>&quot;transmat&quot;</span>

        <span class=n>neworder</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>if</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&quot;transmat&quot;</span><span class=p>:</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_order_from_transmat</span><span class=p>(</span><span class=n>start_state</span><span class=o>=</span><span class=n>start_state</span><span class=p>)</span>
        <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&quot;mode&quot;</span><span class=p>:</span>
            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=n>neworder</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>argsort</span><span class=p>()</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>Exception</span><span class=p>(</span>
                    <span class=s2>&quot;External mapping does not exist yet.First use PoissonHMM.fit_ext()&quot;</span>
                <span class=p>)</span>
        <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&quot;mean&quot;</span><span class=p>:</span>
            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=p>(</span>
                    <span class=n>np</span><span class=o>.</span><span class=n>tile</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]),</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
                    <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span>
                <span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>argsort</span><span class=p>()</span>
                <span class=n>neworder</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>argsort</span><span class=p>()</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>Exception</span><span class=p>(</span>
                    <span class=s2>&quot;External mapping does not exist yet.First use PoissonHMM.fit_ext()&quot;</span>
                <span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;ordering method &#39;&quot;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>method</span><span class=p>)</span> <span class=o>+</span> <span class=s2>&quot;&#39; not supported!&quot;</span>
            <span class=p>)</span>
        <span class=k>return</span> <span class=n>neworder</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_reorder_units_by_ids</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>neworder</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Reorder unit_ids to match that of a BinnedSpikeTrain.</span>

<span class=sd>        WARNING! Modifies self.means_ in-place.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        neworder : list or array-like</span>
<span class=sd>            List of unit IDs specifying the new order. Must be of size (n_units,).</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        self : PoissonHMM</span>
<span class=sd>            The reordered PoissonHMM instance.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; hmm._reorder_units_by_ids([3, 1, 2, 0])</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>neworder</span> <span class=o>=</span> <span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>unit_ids</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>neworder</span><span class=p>]</span>

        <span class=n>oldorder</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>neworder</span><span class=p>)))</span>
        <span class=k>for</span> <span class=n>oi</span><span class=p>,</span> <span class=n>ni</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>neworder</span><span class=p>):</span>
            <span class=n>frm</span> <span class=o>=</span> <span class=n>oldorder</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>ni</span><span class=p>)</span>
            <span class=n>to</span> <span class=o>=</span> <span class=n>oi</span>
            <span class=n>swap_cols</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>means_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_unit_ids</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>_unit_ids</span><span class=p>[</span><span class=n>to</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_unit_ids</span><span class=p>[</span><span class=n>to</span><span class=p>],</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_unit_ids</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span>
            <span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_unit_labels</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>_unit_labels</span><span class=p>[</span><span class=n>to</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_unit_labels</span><span class=p>[</span><span class=n>to</span><span class=p>],</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_unit_labels</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span>
            <span class=p>)</span>
            <span class=c1># TODO: re-build unit tags (tag system not yet implemented)</span>
            <span class=n>oldorder</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>to</span><span class=p>]</span> <span class=o>=</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>to</span><span class=p>],</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>frm</span><span class=p>]</span>

        <span class=k>return</span> <span class=bp>self</span>

    <span class=k>def</span><span class=w> </span><span class=nf>reorder_states</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>neworder</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Reorder internal HMM states according to a specified order.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        neworder : list or array-like</span>
<span class=sd>            List of state indices specifying the new order. Must be of size (n_components,).</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; hmm.reorder_states([2, 0, 1])</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>oldorder</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>neworder</span><span class=p>)))</span>
        <span class=k>for</span> <span class=n>oi</span><span class=p>,</span> <span class=n>ni</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>neworder</span><span class=p>):</span>
            <span class=n>frm</span> <span class=o>=</span> <span class=n>oldorder</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>ni</span><span class=p>)</span>
            <span class=n>to</span> <span class=o>=</span> <span class=n>oi</span>
            <span class=n>swap_cols</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>transmat_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
            <span class=n>swap_rows</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>transmat_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
            <span class=n>swap_rows</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>means_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=n>swap_rows</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>[</span><span class=n>to</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>[</span><span class=n>to</span><span class=p>],</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span>
            <span class=p>)</span>
            <span class=n>oldorder</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>to</span><span class=p>]</span> <span class=o>=</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>to</span><span class=p>],</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>frm</span><span class=p>]</span>

    <span class=k>def</span><span class=w> </span><span class=nf>assume_attributes</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>binnedSpikeTrainArray</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Assume subset of attributes from a BinnedSpikeTrainArray.</span>

<span class=sd>        This is used primarily to enable the sampling of sequences after a model has been fit.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        binnedSpikeTrainArray : BinnedSpikeTrainArray</span>
<span class=sd>            The BinnedSpikeTrainArray instance from which to copy attributes.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_ds</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>warn</span><span class=p>(</span><span class=s2>&quot;PoissonHMM(BinnedSpikeTrain) attributes already exist.&quot;</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>attrib</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>__attributes__</span><span class=p>:</span>
            <span class=n>exec</span><span class=p>(</span><span class=s2>&quot;self.&quot;</span> <span class=o>+</span> <span class=n>attrib</span> <span class=o>+</span> <span class=s2>&quot; = binnedSpikeTrainArray.&quot;</span> <span class=o>+</span> <span class=n>attrib</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_unit_ids</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>binnedSpikeTrainArray</span><span class=o>.</span><span class=n>unit_ids</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_unit_labels</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>binnedSpikeTrainArray</span><span class=o>.</span><span class=n>unit_labels</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_unit_tags</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>binnedSpikeTrainArray</span><span class=o>.</span><span class=n>unit_tags</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_has_same_unit_id_order</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>unit_ids</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Check if the provided unit_ids are in the same order as the model&#39;s unit_ids.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        unit_ids : list or array-like</span>
<span class=sd>            List of unit IDs to compare.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        bool</span>
<span class=sd>            True if the unit_ids are in the same order, False otherwise.</span>

<span class=sd>        Raises</span>
<span class=sd>        ------</span>
<span class=sd>        TypeError</span>
<span class=sd>            If the number of unit_ids does not match.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_unit_ids</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>return</span> <span class=kc>True</span>
        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>unit_ids</span><span class=p>)</span> <span class=o>!=</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>unit_ids</span><span class=p>):</span>
            <span class=k>raise</span> <span class=ne>TypeError</span><span class=p>(</span><span class=s2>&quot;Incorrect number of unit_ids encountered!&quot;</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>unit_id</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>unit_ids</span><span class=p>):</span>
            <span class=k>if</span> <span class=n>unit_id</span> <span class=o>!=</span> <span class=bp>self</span><span class=o>.</span><span class=n>unit_ids</span><span class=p>[</span><span class=n>ii</span><span class=p>]:</span>
                <span class=k>return</span> <span class=kc>False</span>
        <span class=k>return</span> <span class=kc>True</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_sliding_window_array</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>bst</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Returns an unwrapped data array by sliding w bins one bin at a time.</span>

<span class=sd>        If w==1, then bins are non-overlapping.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        bst : BinnedSpikeTrainArray</span>
<span class=sd>            Input with data array of shape (n_units, n_bins).</span>
<span class=sd>        w : int, optional</span>
<span class=sd>            Window size (number of bins). Default is 1.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        unwrapped : np.ndarray</span>
<span class=sd>            New data array of shape (n_sliding_bins, n_units).</span>
<span class=sd>        lengths : np.ndarray</span>
<span class=sd>            Array of shape (n_sliding_bins,) indicating the lengths of each window.</span>

<span class=sd>        Raises</span>
<span class=sd>        ------</span>
<span class=sd>        NotImplementedError</span>
<span class=sd>            If bst is not a BinnedSpikeTrainArray.</span>
<span class=sd>        AssertionError</span>
<span class=sd>            If w is not a positive integer.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; unwrapped, lengths = hmm._sliding_window_array(bst, w=3)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>w</span> <span class=o>=</span> <span class=mi>1</span>
        <span class=k>assert</span> <span class=nb>float</span><span class=p>(</span><span class=n>w</span><span class=p>)</span><span class=o>.</span><span class=n>is_integer</span><span class=p>(),</span> <span class=s2>&quot;w must be a positive integer!&quot;</span>
        <span class=k>assert</span> <span class=n>w</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>,</span> <span class=s2>&quot;w must be a positive integer!&quot;</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>bst</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;support for other datatypes not yet implemented!&quot;</span>
            <span class=p>)</span>

        <span class=c1># potentially re-organize internal observation matrix to be</span>
        <span class=c1># compatible with BinnedSpikeTrainArray</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>_has_same_unit_id_order</span><span class=p>(</span><span class=n>bst</span><span class=o>.</span><span class=n>unit_ids</span><span class=p>):</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_reorder_units_by_ids</span><span class=p>(</span><span class=n>bst</span><span class=o>.</span><span class=n>unit_ids</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>w</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>bst</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>bst</span><span class=o>.</span><span class=n>lengths</span>

        <span class=n>n_units</span><span class=p>,</span> <span class=n>t_bins</span> <span class=o>=</span> <span class=n>bst</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>shape</span>

        <span class=c1># if we decode using multiple bins at a time (w&gt;1) then we have to decode each epoch separately:</span>

        <span class=c1># first, we determine the number of bins we will decode. This requires us to scan over the epochs</span>
        <span class=n>n_bins</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=n>cumlengths</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>bst</span><span class=o>.</span><span class=n>lengths</span><span class=p>)</span>
        <span class=n>lengths</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>bst</span><span class=o>.</span><span class=n>n_epochs</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int</span><span class=p>)</span>
        <span class=n>prev_idx</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>to_idx</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>cumlengths</span><span class=p>):</span>
            <span class=n>datalen</span> <span class=o>=</span> <span class=n>to_idx</span> <span class=o>-</span> <span class=n>prev_idx</span>
            <span class=n>prev_idx</span> <span class=o>=</span> <span class=n>to_idx</span>
            <span class=n>lengths</span><span class=p>[</span><span class=n>ii</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=n>datalen</span> <span class=o>-</span> <span class=n>w</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>

        <span class=n>n_bins</span> <span class=o>=</span> <span class=n>lengths</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

        <span class=n>unwrapped</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>n_units</span><span class=p>,</span> <span class=n>n_bins</span><span class=p>))</span>

        <span class=c1># next, we decode each epoch separately, one bin at a time</span>
        <span class=n>cum_lengths</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>insert</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>lengths</span><span class=p>),</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>

        <span class=n>prev_idx</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>to_idx</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>cumlengths</span><span class=p>):</span>
            <span class=n>data</span> <span class=o>=</span> <span class=n>bst</span><span class=o>.</span><span class=n>data</span><span class=p>[:,</span> <span class=n>prev_idx</span><span class=p>:</span><span class=n>to_idx</span><span class=p>]</span>
            <span class=n>prev_idx</span> <span class=o>=</span> <span class=n>to_idx</span>
            <span class=n>datacum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span>
                <span class=n>data</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span>
            <span class=p>)</span>  <span class=c1># ii&#39;th data segment, with column of zeros prepended</span>
            <span class=n>datacum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>hstack</span><span class=p>((</span><span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>n_units</span><span class=p>,</span> <span class=mi>1</span><span class=p>)),</span> <span class=n>datacum</span><span class=p>))</span>
            <span class=n>re</span> <span class=o>=</span> <span class=n>w</span>  <span class=c1># right edge ptr</span>
            <span class=c1># TODO: check if datalen &lt; w and act appropriately</span>
            <span class=k>if</span> <span class=n>lengths</span><span class=p>[</span><span class=n>ii</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>  <span class=c1># more than one full window fits into data length</span>
                <span class=k>for</span> <span class=n>tt</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>lengths</span><span class=p>[</span><span class=n>ii</span><span class=p>]):</span>
                    <span class=n>obs</span> <span class=o>=</span> <span class=p>(</span>
                        <span class=n>datacum</span><span class=p>[:,</span> <span class=n>re</span><span class=p>]</span> <span class=o>-</span> <span class=n>datacum</span><span class=p>[:,</span> <span class=n>re</span> <span class=o>-</span> <span class=n>w</span><span class=p>]</span>
                    <span class=p>)</span>  <span class=c1># spikes in window of size w</span>
                    <span class=n>re</span> <span class=o>+=</span> <span class=mi>1</span>
                    <span class=n>post_idx</span> <span class=o>=</span> <span class=n>lengths</span><span class=p>[</span><span class=n>ii</span><span class=p>]</span> <span class=o>+</span> <span class=n>tt</span>
                    <span class=n>unwrapped</span><span class=p>[:,</span> <span class=n>post_idx</span><span class=p>]</span> <span class=o>=</span> <span class=n>obs</span>
            <span class=k>else</span><span class=p>:</span>  <span class=c1># only one window can fit in, and perhaps only partially. We just take all the data we can get,</span>
                <span class=c1># and ignore the scaling problem where the window size is now possibly less than bst.ds*w</span>
                <span class=n>post_idx</span> <span class=o>=</span> <span class=n>cum_lengths</span><span class=p>[</span><span class=n>ii</span><span class=p>]</span>
                <span class=n>obs</span> <span class=o>=</span> <span class=n>datacum</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span>  <span class=c1># spikes in window of size at most w</span>
                <span class=n>unwrapped</span><span class=p>[:,</span> <span class=n>post_idx</span><span class=p>]</span> <span class=o>=</span> <span class=n>obs</span>

        <span class=k>return</span> <span class=n>unwrapped</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>lengths</span>

    <span class=k>def</span><span class=w> </span><span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>algorithm</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Find the most likely state sequence corresponding to ``X``.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        X : array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>            Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>            WARNING: Each decoding window is assumed to be similar in size to those used during training.</span>
<span class=sd>            If not, the tuning curves have to be scaled appropriately!</span>
<span class=sd>        lengths : array-like of int, shape (n_sequences,), optional</span>
<span class=sd>            Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>            Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>
<span class=sd>        w : int, optional</span>
<span class=sd>            Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</span>
<span class=sd>        algorithm : str, optional</span>
<span class=sd>            Decoder algorithm to be used (see DECODER_ALGORITHMS).</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        logprob : float or list of float</span>
<span class=sd>            Log probability of the produced state sequence.</span>
<span class=sd>        state_sequence : np.ndarray or list of np.ndarray</span>
<span class=sd>            Labels for each sample from ``X`` obtained via the given decoder algorithm.</span>
<span class=sd>        centers : np.ndarray or list of np.ndarray</span>
<span class=sd>            Time-centers of all bins contained in ``X``.</span>

<span class=sd>        See Also</span>
<span class=sd>        --------</span>
<span class=sd>        score_samples : Compute the log probability under the model and posteriors.</span>
<span class=sd>        score : Compute the log probability under the model.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; logprob, state_seq, centers = hmm.decode(bst)</span>
<span class=sd>        &gt;&gt;&gt; logprob, state_seq, centers = hmm.decode(X, algorithm=&quot;viterbi&quot;)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>algorithm</span><span class=o>=</span><span class=n>algorithm</span><span class=p>),</span> <span class=kc>None</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>logprobs</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=n>state_sequences</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=n>centers</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
                <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>seq</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
                <span class=n>logprob</span><span class=p>,</span> <span class=n>state_sequence</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_decode</span><span class=p>(</span>
                    <span class=bp>self</span><span class=p>,</span> <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>algorithm</span><span class=o>=</span><span class=n>algorithm</span>
                <span class=p>)</span>
                <span class=n>logprobs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>logprob</span><span class=p>)</span>
                <span class=n>state_sequences</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>state_sequence</span><span class=p>)</span>
                <span class=n>centers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>seq</span><span class=o>.</span><span class=n>centers</span><span class=p>)</span>
            <span class=k>return</span> <span class=n>logprobs</span><span class=p>,</span> <span class=n>state_sequences</span><span class=p>,</span> <span class=n>centers</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_decode_from_lambda_only</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Decode using the observation (lambda) matrix only (i.e., pure memoryless decoding).</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        X : array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>            Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>            WARNING: Each decoding window is assumed to be similar in size to those used during training.</span>
<span class=sd>            If not, the tuning curves have to be scaled appropriately!</span>
<span class=sd>        lengths : array-like of int, shape (n_sequences,), optional</span>
<span class=sd>            Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>            Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        posteriors : list of np.ndarray</span>
<span class=sd>            State-membership probabilities for each sample in ``X``; one array for each sequence in X.</span>
<span class=sd>        state_sequences : list of np.ndarray</span>
<span class=sd>            Labels for each sample from ``X``; one array for each sequence in X.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; posteriors, state_sequences = hmm._decode_from_lambda_only(bst)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;Not yet implemented!&quot;</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>ratemap</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>means_</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
            <span class=c1># make sure X and ratemap have same unit_id ordering!</span>
            <span class=n>neworder</span> <span class=o>=</span> <span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>unit_ids</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>X</span><span class=o>.</span><span class=n>unit_ids</span><span class=p>]</span>
            <span class=n>oldorder</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>neworder</span><span class=p>)))</span>
            <span class=k>for</span> <span class=n>oi</span><span class=p>,</span> <span class=n>ni</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>neworder</span><span class=p>):</span>
                <span class=n>frm</span> <span class=o>=</span> <span class=n>oldorder</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>ni</span><span class=p>)</span>
                <span class=n>to</span> <span class=o>=</span> <span class=n>oi</span>
                <span class=n>swap_rows</span><span class=p>(</span><span class=n>ratemap</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
                <span class=n>oldorder</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>to</span><span class=p>]</span> <span class=o>=</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>to</span><span class=p>],</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>frm</span><span class=p>]</span>

            <span class=n>posteriors</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=n>state_sequences</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
                <span class=n>posteriors_</span><span class=p>,</span> <span class=n>cumlengths</span><span class=p>,</span> <span class=n>mode_pth</span><span class=p>,</span> <span class=n>mean_pth</span> <span class=o>=</span> <span class=n>decode1D</span><span class=p>(</span>
                    <span class=n>bst</span><span class=o>=</span><span class=n>seq</span><span class=p>,</span> <span class=n>ratemap</span><span class=o>=</span><span class=n>ratemap</span>
                <span class=p>)</span>
                <span class=c1># nanlocs = np.argwhere(np.isnan(mode_pth))</span>
                <span class=c1># state_sequences_ = mode_pth.astype(int)</span>
                <span class=n>state_sequences_</span> <span class=o>=</span> <span class=n>mode_pth</span>
                <span class=n>posteriors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>posteriors_</span><span class=p>)</span>
                <span class=n>state_sequences</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>state_sequences_</span><span class=p>)</span>

            <span class=k>return</span> <span class=n>posteriors</span><span class=p>,</span> <span class=n>state_sequences</span>

    <span class=k>def</span><span class=w> </span><span class=nf>predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>returnLengths</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Compute the posterior probability for each state in the model.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        X : array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>            Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>        lengths : array-like of int, shape (n_sequences,), optional</span>
<span class=sd>            Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>            Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>
<span class=sd>        w : int, optional</span>
<span class=sd>            Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</span>
<span class=sd>        returnLengths : bool, optional</span>
<span class=sd>            If True, also return the lengths array.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        posteriors : np.ndarray</span>
<span class=sd>            Array of shape (n_components, n_samples) with state-membership probabilities for each sample from ``X``.</span>
<span class=sd>        lengths : np.ndarray, optional</span>
<span class=sd>            Returned if returnLengths is True; array of sequence lengths.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; posteriors = hmm.predict_proba(bst)</span>
<span class=sd>        &gt;&gt;&gt; posteriors, lengths = hmm.predict_proba(bst, returnLengths=True)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;we have a &quot;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>X</span><span class=p>)))</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
            <span class=k>if</span> <span class=n>returnLengths</span><span class=p>:</span>
                <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
                <span class=p>),</span> <span class=n>lengths</span>
            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>))</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
            <span class=k>if</span> <span class=n>returnLengths</span><span class=p>:</span>
                <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
                <span class=p>),</span> <span class=n>lengths</span>
            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
            <span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Find the most likely state sequence corresponding to ``X``.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        X : array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>            Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>        lengths : array-like of int, shape (n_sequences,), optional</span>
<span class=sd>            Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>            Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>
<span class=sd>        w : int, optional</span>
<span class=sd>            Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        state_sequence : np.ndarray or list of np.ndarray</span>
<span class=sd>            Labels for each sample from ``X``.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; state_seq = hmm.predict(bst)</span>
<span class=sd>        &gt;&gt;&gt; state_seq = hmm.predict(X)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>_</span><span class=p>,</span> <span class=n>state_sequences</span><span class=p>,</span> <span class=n>centers</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>state_sequences</span>

    <span class=k>def</span><span class=w> </span><span class=nf>sample</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_samples</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Generate random samples from the model.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        n_samples : int</span>
<span class=sd>            Number of samples to generate.</span>
<span class=sd>        random_state : RandomState or int, optional</span>
<span class=sd>            A random number generator instance or seed. If None, the object&#39;s random_state is used.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        X : np.ndarray</span>
<span class=sd>            Feature matrix of shape (n_samples, n_features).</span>
<span class=sd>        state_sequence : np.ndarray</span>
<span class=sd>            State sequence produced by the model.</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        &gt;&gt;&gt; X, states = hmm.sample(n_samples=100)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sample</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_samples</span><span class=o>=</span><span class=n>n_samples</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=n>random_state</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>score_samples</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Compute the log probability under the model and compute posteriors.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        X : array-like, shape (n_samples, n_features)</span>
<span class=sd>            Feature matrix of individual samples.</span>
<span class=sd>            OR</span>
<span class=sd>            nelpy.BinnedSpikeTrainArray</span>
<span class=sd>        lengths : array-like of integers, shape (n_sequences, ), optional</span>
<span class=sd>            Lengths of the individual sequences in ``X``. The sum of</span>
<span class=sd>            these should be ``n_samples``. This is not used when X is</span>
<span class=sd>            a nelpy.BinnedSpikeTrainArray, in which case the lenghts are</span>
<span class=sd>            automatically inferred.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        logprob : float</span>
<span class=sd>            Log likelihood of ``X``; one scalar for each sequence in X.</span>

<span class=sd>        posteriors : array, shape (n_components, n_samples)</span>
<span class=sd>            State-membership probabilities for each sample in ``X``;</span>
<span class=sd>            one array for each sequence in X.</span>

<span class=sd>        See Also</span>
<span class=sd>        --------</span>
<span class=sd>        score : Compute the log probability under the model.</span>
<span class=sd>        decode : Find most likely state sequence corresponding to ``X``.</span>
<span class=sd>        &quot;&quot;&quot;</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
            <span class=n>logprobs</span><span class=p>,</span> <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score_samples</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
            <span class=k>return</span> <span class=p>(</span>
                <span class=n>logprobs</span><span class=p>,</span>
                <span class=n>posteriors</span><span class=p>,</span>
            <span class=p>)</span>  <span class=c1># .T why does this transpose affect hmm.predict_proba!!!????</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>logprobs</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=n>posteriors</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
                <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>seq</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
                <span class=n>logprob</span><span class=p>,</span> <span class=n>posterior</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score_samples</span><span class=p>(</span>
                    <span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span>
                <span class=p>)</span>
                <span class=n>logprobs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>logprob</span><span class=p>)</span>
                <span class=n>posteriors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>posterior</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
            <span class=k>return</span> <span class=n>logprobs</span><span class=p>,</span> <span class=n>posteriors</span>

    <span class=k>def</span><span class=w> </span><span class=nf>score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Compute the log probability under the model.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        X : array-like, shape (n_samples, n_features)</span>
<span class=sd>            Feature matrix of individual samples.</span>
<span class=sd>            OR</span>
<span class=sd>            nelpy.BinnedSpikeTrainArray</span>
<span class=sd>        lengths : array-like of integers, shape (n_sequences, ), optional</span>
<span class=sd>            Lengths of the individual sequences in ``X``. The sum of</span>
<span class=sd>            these should be ``n_samples``. This is not used when X is</span>
<span class=sd>            a nelpy.BinnedSpikeTrainArray, in which case the lenghts are</span>
<span class=sd>            automatically inferred.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        logprob : float, or list of floats</span>
<span class=sd>            Log likelihood of ``X``; one scalar for each sequence in X.</span>

<span class=sd>        See Also</span>
<span class=sd>        --------</span>
<span class=sd>        score_samples : Compute the log probability under the model and</span>
<span class=sd>            posteriors.</span>
<span class=sd>        decode : Find most likely state sequence corresponding to ``X``.</span>
<span class=sd>        &quot;&quot;&quot;</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>logprobs</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
                <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>seq</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
                <span class=n>logprob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
                <span class=n>logprobs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>logprob</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>logprobs</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_cum_score_per_bin</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Compute the log probability under the model, cumulatively for each bin per event.&quot;&quot;&quot;</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>logprobs</span> <span class=o>=</span> <span class=p>[]</span>
            <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
                <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>seq</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
                <span class=n>n_bins</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>windowed_arr</span><span class=o>.</span><span class=n>shape</span>
                <span class=k>for</span> <span class=n>ii</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n_bins</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
                    <span class=n>logprob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>windowed_arr</span><span class=p>[:</span><span class=n>ii</span><span class=p>,</span> <span class=p>:])</span>
                    <span class=n>logprobs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>logprob</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>logprobs</span>

    <span class=k>def</span><span class=w> </span><span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Estimate model parameters using nelpy objects.</span>

<span class=sd>        An initialization step is performed before entering the</span>
<span class=sd>        EM-algorithm. If you want to avoid this step for a subset of</span>
<span class=sd>        the parameters, pass proper ``init_params`` keyword argument</span>
<span class=sd>        to estimator&#39;s constructor.</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        X : array-like, shape (n_samples, n_units)</span>
<span class=sd>            Feature matrix of individual samples.</span>
<span class=sd>            OR</span>
<span class=sd>            nelpy.BinnedSpikeTrainArray</span>
<span class=sd>        lengths : array-like of integers, shape (n_sequences, )</span>
<span class=sd>            Lengths of the individual sequences in ``X``. The sum of</span>
<span class=sd>            these should be ``n_samples``. This is not used when X is</span>
<span class=sd>            a nelpy.BinnedSpikeTrainArray, in which case the lenghts are</span>
<span class=sd>            automatically inferred.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        self : object</span>
<span class=sd>            Returns self.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
            <span class=c1># adopt unit_ids, unit_labels, etc. from BinnedSpikeTrain</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>assume_attributes</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
        <span class=k>return</span> <span class=bp>self</span>

    <span class=k>def</span><span class=w> </span><span class=nf>fit_ext</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>X</span><span class=p>,</span>
        <span class=n>ext</span><span class=p>,</span>
        <span class=n>n_extern</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>save</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>normalize</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>normalize_by_occupancy</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Learn a mapping from the internal state space, to an external</span>
<span class=sd>        augmented space (e.g. position).</span>

<span class=sd>        Returns a row-normalized version of (n_states, n_ext), that</span>
<span class=sd>        is, a distribution over external bins for each state.</span>

<span class=sd>        X : BinnedSpikeTrainArray</span>

<span class=sd>        ext : array-like</span>
<span class=sd>            array of external correlates (n_bins, )</span>
<span class=sd>        n_extern : int</span>
<span class=sd>            number of extern variables, with range 0,.. n_extern-1</span>
<span class=sd>        save : bool</span>
<span class=sd>            stores extern in PoissonHMM if true, discards it if not</span>
<span class=sd>        w:</span>
<span class=sd>        normalize : bool</span>
<span class=sd>            If True, then normalize each state to have a distribution over ext.</span>
<span class=sd>        occupancy : array of bin counts</span>
<span class=sd>            Default is all ones (uniform).</span>

<span class=sd>        self.extern_ of size (n_components, n_extern)</span>
<span class=sd>        &quot;&quot;&quot;</span>

        <span class=k>if</span> <span class=n>n_extern</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>n_extern</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>unique</span><span class=p>(</span><span class=n>ext</span><span class=p>))</span>
            <span class=n>ext_map</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n_extern</span><span class=p>)</span>
            <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>ele</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>unique</span><span class=p>(</span><span class=n>ext</span><span class=p>)):</span>
                <span class=n>ext_map</span><span class=p>[</span><span class=n>ele</span><span class=p>]</span> <span class=o>=</span> <span class=n>ii</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>ext_map</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n_extern</span><span class=p>)</span>

        <span class=c1># idea: here, ext can be anything, and n_extern should be range</span>
        <span class=c1># we can e.g., define extern correlates {leftrun, rightrun} and</span>
        <span class=c1># fit the mapping. This is not expected to be good at all for</span>
        <span class=c1># most states, but it could allow us to identify a state or two</span>
        <span class=c1># for which there *might* be a strong predictive relationship.</span>
        <span class=c1># In this way, the binning, etc. should be done external to this</span>
        <span class=c1># function, but it might still make sense to encapsulate it as</span>
        <span class=c1># a helper function inside PoissonHMM?</span>

        <span class=c1># xpos, ypos = get_position(exp_data[&#39;session1&#39;][&#39;posdf&#39;], bst.centers)</span>
        <span class=c1># x0=0; xl=100; n_extern=50</span>
        <span class=c1># xx_left = np.linspace(x0,xl,n_extern+1)</span>
        <span class=c1># xx_mid = np.linspace(x0,xl,n_extern+1)[:-1]; xx_mid += (xx_mid[1]-xx_mid[0])/2</span>
        <span class=c1># ext = np.digitize(xpos, xx_left) - 1 # spatial bin numbers</span>

        <span class=n>extern</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=n>n_extern</span><span class=p>))</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
            <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>

        <span class=n>posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>vstack</span><span class=p>(</span><span class=n>posteriors</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>  <span class=c1># 1D array of states, of length n_bins</span>

        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>posteriors</span><span class=p>)</span> <span class=o>!=</span> <span class=nb>len</span><span class=p>(</span><span class=n>ext</span><span class=p>):</span>
            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;ext must have same length as decoded state sequence!&quot;</span><span class=p>)</span>

        <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>posterior</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>posteriors</span><span class=p>):</span>
            <span class=k>if</span> <span class=ow>not</span> <span class=n>np</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>ext</span><span class=p>[</span><span class=n>ii</span><span class=p>]):</span>
                <span class=n>extern</span><span class=p>[:,</span> <span class=n>ext_map</span><span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=n>ext</span><span class=p>[</span><span class=n>ii</span><span class=p>])]]</span> <span class=o>+=</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>posterior</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>normalize_by_occupancy</span><span class=p>:</span>
            <span class=n>occupancy</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>ext</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=n>n_extern</span><span class=p>,</span> <span class=nb>range</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_extern</span><span class=p>])</span>
            <span class=n>occupancy</span><span class=p>[</span><span class=n>occupancy</span> <span class=o>==</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
            <span class=n>occupancy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>atleast_2d</span><span class=p>(</span><span class=n>occupancy</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>occupancy</span> <span class=o>=</span> <span class=mi>1</span>

        <span class=n>extern</span> <span class=o>=</span> <span class=n>extern</span> <span class=o>/</span> <span class=n>occupancy</span>

        <span class=k>if</span> <span class=n>normalize</span><span class=p>:</span>
            <span class=c1># normalize extern tuning curves:</span>
            <span class=n>rowsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>tile</span><span class=p>(</span><span class=n>extern</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=p>(</span><span class=n>n_extern</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>T</span>
            <span class=n>rowsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>rowsum</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=mi>1</span><span class=p>,</span> <span class=n>rowsum</span><span class=p>)</span>
            <span class=n>extern</span> <span class=o>=</span> <span class=n>extern</span> <span class=o>/</span> <span class=n>rowsum</span>

        <span class=k>if</span> <span class=n>save</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=o>=</span> <span class=n>extern</span>
            <span class=c1># self._extern_map = ext_map</span>

        <span class=k>return</span> <span class=n>extern</span>

    <span class=k>def</span><span class=w> </span><span class=nf>fit_ext2</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>ext</span><span class=p>,</span> <span class=n>n_extern</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Learn a mapping from the internal state space, to an external</span>
<span class=sd>        augmented space (e.g. position).</span>

<span class=sd>        Returns a column-normalized version of (n_states, n_ext), that</span>
<span class=sd>        is, a distribution over states for each extern bin.</span>

<span class=sd>        X : BinnedSpikeTrainArray</span>

<span class=sd>        ext : array-like</span>
<span class=sd>            array of external correlates (n_bins, )</span>
<span class=sd>        n_extern : int</span>
<span class=sd>            number of extern variables, with range 0,.. n_extern-1</span>

<span class=sd>        save : bool</span>
<span class=sd>            stores extern in PoissonHMM if true, discards it if not</span>

<span class=sd>        self.extern_ of size (n_components, n_extern)</span>
<span class=sd>        &quot;&quot;&quot;</span>

        <span class=n>ext_map</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n_extern</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>n_extern</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>n_extern</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>unique</span><span class=p>(</span><span class=n>ext</span><span class=p>))</span>
            <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>ele</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>unique</span><span class=p>(</span><span class=n>ext</span><span class=p>)):</span>
                <span class=n>ext_map</span><span class=p>[</span><span class=n>ele</span><span class=p>]</span> <span class=o>=</span> <span class=n>ii</span>

        <span class=c1># idea: here, ext can be anything, and n_extern should be range</span>
        <span class=c1># we can e.g., define extern correlates {leftrun, rightrun} and</span>
        <span class=c1># fit the mapping. This is not expexted to be good at all for</span>
        <span class=c1># most states, but it could allow us to identify a state or two</span>
        <span class=c1># for which there *might* be a strong predictive relationship.</span>
        <span class=c1># In this way, the binning, etc. should be done external to this</span>
        <span class=c1># function, but it might still make sense to encapsulate it as</span>
        <span class=c1># a helper function inside PoissonHMM?</span>

        <span class=c1># xpos, ypos = get_position(exp_data[&#39;session1&#39;][&#39;posdf&#39;], bst.centers)</span>
        <span class=c1># x0=0; xl=100; n_extern=50</span>
        <span class=c1># xx_left = np.linspace(x0,xl,n_extern+1)</span>
        <span class=c1># xx_mid = np.linspace(x0,xl,n_extern+1)[:-1]; xx_mid += (xx_mid[1]-xx_mid[0])/2</span>
        <span class=c1># ext = np.digitize(xpos, xx_left) - 1 # spatial bin numbers</span>

        <span class=n>extern</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=n>n_extern</span><span class=p>))</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
            <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
        <span class=n>posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>vstack</span><span class=p>(</span><span class=n>posteriors</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>  <span class=c1># 1D array of states, of length n_bins</span>

        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>posteriors</span><span class=p>)</span> <span class=o>!=</span> <span class=nb>len</span><span class=p>(</span><span class=n>ext</span><span class=p>):</span>
            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;ext must have same length as decoded state sequence!&quot;</span><span class=p>)</span>

        <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>posterior</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>posteriors</span><span class=p>):</span>
            <span class=k>if</span> <span class=ow>not</span> <span class=n>np</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>ext</span><span class=p>[</span><span class=n>ii</span><span class=p>]):</span>
                <span class=n>extern</span><span class=p>[:,</span> <span class=n>ext_map</span><span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=n>ext</span><span class=p>[</span><span class=n>ii</span><span class=p>])]]</span> <span class=o>+=</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>posterior</span><span class=p>)</span>

        <span class=c1># normalize extern tuning curves:</span>
        <span class=n>colsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>tile</span><span class=p>(</span><span class=n>extern</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>),</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
        <span class=n>colsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>colsum</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=mi>1</span><span class=p>,</span> <span class=n>colsum</span><span class=p>)</span>
        <span class=n>extern</span> <span class=o>=</span> <span class=n>extern</span> <span class=o>/</span> <span class=n>colsum</span>

        <span class=k>return</span> <span class=n>extern</span>

    <span class=k>def</span><span class=w> </span><span class=nf>decode_ext</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>ext_shape</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Find memoryless most likely state sequence corresponding to ``X``,</span>
<span class=sd>        (that is, the symbol-by-symbol MAP sequence) and then map those</span>
<span class=sd>        states to an associated external representation (e.g., position).</span>

<span class=sd>        Parameters</span>
<span class=sd>        ----------</span>
<span class=sd>        X : array-like, shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>            Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>        lengths : array-like of integers, shape (n_sequences, ), optional</span>
<span class=sd>            Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>            Not used when X is a nelpy.BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>
<span class=sd>        w : int, optional</span>
<span class=sd>            Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</span>
<span class=sd>        ext_shape : tuple, optional</span>
<span class=sd>            Shape of the external variables.</span>

<span class=sd>        Returns</span>
<span class=sd>        -------</span>
<span class=sd>        ext_posteriors : np.ndarray</span>
<span class=sd>            Array of shape (n_extern, n_samples) with state-membership probabilities for each sample in ``X``.</span>
<span class=sd>        bdries : np.ndarray</span>
<span class=sd>            Array of bin boundaries.</span>
<span class=sd>        mode_pth : np.ndarray</span>
<span class=sd>            Most likely external variable sequence (mode path).</span>
<span class=sd>        mean_pth : np.ndarray</span>
<span class=sd>            Mean external variable sequence (mean path).</span>

<span class=sd>        Examples</span>
<span class=sd>        --------</span>
<span class=sd>        For 1D external variables:</span>
<span class=sd>        &gt;&gt;&gt; posterior_pos, bdries, mode_pth, mean_pth = hmm.decode_ext(</span>
<span class=sd>        ...     bst_no_ripple, ext_shape=(vtc.n_bins,)</span>
<span class=sd>        ... )</span>
<span class=sd>        &gt;&gt;&gt; mean_pth = vtc.bins[0] + mean_pth * (vtc.bins[-1] - vtc.bins[0])</span>

<span class=sd>        For 2D external variables:</span>
<span class=sd>        &gt;&gt;&gt; posterior_, bdries_, mode_pth_, mean_pth_ = hmm.decode_ext(</span>
<span class=sd>        ...     bst, ext_shape=(ext_nx, ext_ny)</span>
<span class=sd>        ... )</span>
<span class=sd>        &gt;&gt;&gt; mean_pth_[0, :] = vtc2d.xbins[0] + mean_pth_[0, :] * (</span>
<span class=sd>        ...     vtc2d.xbins[-1] - vtc2d.xbins[0]</span>
<span class=sd>        ... )</span>
<span class=sd>        &gt;&gt;&gt; mean_pth_[1, :] = vtc2d.ybins[0] + mean_pth_[1, :] * (</span>
<span class=sd>        ...     vtc2d.ybins[-1] - vtc2d.ybins[0]</span>
<span class=sd>        ... )</span>
<span class=sd>        &quot;&quot;&quot;</span>

        <span class=n>_</span><span class=p>,</span> <span class=n>n_extern</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>shape</span>

        <span class=k>if</span> <span class=n>ext_shape</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>ext_shape</span> <span class=o>=</span> <span class=n>n_extern</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
            <span class=c1># assume we have a feature matrix</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;not implemented yet.&quot;</span><span class=p>)</span>
            <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                    <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
                <span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># we have a BinnedSpikeTrainArray</span>
            <span class=k>pass</span>
        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>ext_shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
            <span class=c1># do old style decoding</span>
            <span class=c1># TODO: this can be improved to be like the 2D case!</span>
            <span class=n>state_posteriors</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span>
                <span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>,</span> <span class=n>returnLengths</span><span class=o>=</span><span class=kc>True</span>
            <span class=p>)</span>
            <span class=c1># fixy = np.mean(self._extern_ * np.arange(n_extern), axis=1)</span>
            <span class=c1># mean_pth = np.sum(state_posteriors.T*fixy, axis=1) # range 0 to 1</span>
            <span class=n>ext_posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span>
                <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n_extern</span><span class=p>))</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>state_posteriors</span>
            <span class=p>)</span>
            <span class=c1># normalize ext_posterior distributions:</span>
            <span class=n>ext_posteriors</span> <span class=o>=</span> <span class=n>ext_posteriors</span> <span class=o>/</span> <span class=n>ext_posteriors</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
            <span class=n>mean_pth</span> <span class=o>=</span> <span class=p>(</span>
                <span class=n>ext_posteriors</span><span class=o>.</span><span class=n>T</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>atleast_2d</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n_extern</span><span class=p>))</span>
            <span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>mode_pth</span> <span class=o>=</span> <span class=p>(</span>
                <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>ext_posteriors</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span> <span class=o>/</span> <span class=n>n_extern</span>
            <span class=p>)</span>  <span class=c1># range 0 to n_extern</span>

        <span class=k>elif</span> <span class=nb>len</span><span class=p>(</span><span class=n>ext_shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>
            <span class=n>ext_posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>ext_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>X</span><span class=o>.</span><span class=n>n_bins</span><span class=p>))</span>
            <span class=c1># get posterior distribution over states, of size (num_States, n_extern)</span>
            <span class=n>state_posteriors</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span>
                <span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>,</span> <span class=n>returnLengths</span><span class=o>=</span><span class=kc>True</span>
            <span class=p>)</span>
            <span class=c1># for each bin, compute the distribution in the external domain</span>
            <span class=k>for</span> <span class=n>bb</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>n_bins</span><span class=p>):</span>
                <span class=n>ext_posteriors</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>bb</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span>
                    <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=o>*</span> <span class=n>state_posteriors</span><span class=p>[:,</span> <span class=p>[</span><span class=n>bb</span><span class=p>]])</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>),</span> <span class=n>ext_shape</span>
                <span class=p>)</span>
            <span class=c1># now compute mean and mode paths</span>
            <span class=n>expected_x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span>
                <span class=p>(</span>
                    <span class=n>ext_posteriors</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
                    <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>atleast_2d</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span><span class=o>.</span><span class=n>T</span>
                <span class=p>),</span>
                <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
            <span class=p>)</span>
            <span class=n>expected_y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span>
                <span class=p>(</span>
                    <span class=n>ext_posteriors</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
                    <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>atleast_2d</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]))</span><span class=o>.</span><span class=n>T</span>
                <span class=p>),</span>
                <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
            <span class=p>)</span>
            <span class=n>mean_pth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>vstack</span><span class=p>((</span><span class=n>expected_x</span><span class=p>,</span> <span class=n>expected_y</span><span class=p>))</span>

            <span class=n>mode_pth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>n_bins</span><span class=p>))</span>
            <span class=k>for</span> <span class=n>tt</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>n_bins</span><span class=p>):</span>
                <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>any</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>ext_posteriors</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>tt</span><span class=p>])):</span>
                    <span class=n>mode_pth</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>tt</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
                    <span class=n>mode_pth</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>tt</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
                <span class=k>else</span><span class=p>:</span>
                    <span class=n>x_</span><span class=p>,</span> <span class=n>y_</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>unravel_index</span><span class=p>(</span>
                        <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>ext_posteriors</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>tt</span><span class=p>]),</span>
                        <span class=p>(</span><span class=n>ext_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]),</span>
                    <span class=p>)</span>
                    <span class=n>mode_pth</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>tt</span><span class=p>]</span> <span class=o>=</span> <span class=n>x_</span> <span class=o>/</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
                    <span class=n>mode_pth</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=n>tt</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_</span> <span class=o>/</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>

            <span class=n>ext_posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>ext_posteriors</span><span class=p>,</span> <span class=n>axes</span><span class=o>=</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>TypeError</span><span class=p>(</span><span class=s2>&quot;shape not currently supported!&quot;</span><span class=p>)</span>

        <span class=n>bdries</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>lengths</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>ext_posteriors</span><span class=p>,</span> <span class=n>bdries</span><span class=p>,</span> <span class=n>mode_pth</span><span class=p>,</span> <span class=n>mean_pth</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_plot_external</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=o>*</span><span class=p>,</span>
        <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>),</span>
        <span class=n>sharey</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>labelstates</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>ec</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>fillcolor</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>lw</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
    <span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;plot the externally associated state&lt;--&gt;extern mapping</span>

<span class=sd>        WARNING! This function is not complete, and hence &#39;private&#39;,</span>
<span class=sd>        and may be moved somewhere else later on.</span>
<span class=sd>        &quot;&quot;&quot;</span>

        <span class=k>if</span> <span class=n>labelstates</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>labelstates</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>]</span>
        <span class=k>if</span> <span class=n>ec</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>ec</span> <span class=o>=</span> <span class=s2>&quot;k&quot;</span>
        <span class=k>if</span> <span class=n>fillcolor</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>fillcolor</span> <span class=o>=</span> <span class=s2>&quot;gray&quot;</span>
        <span class=k>if</span> <span class=n>lw</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>lw</span> <span class=o>=</span> <span class=mf>1.5</span>

        <span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>subplots</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=n>figsize</span><span class=p>,</span> <span class=n>sharey</span><span class=o>=</span><span class=n>sharey</span><span class=p>)</span>

        <span class=n>xvals</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>T</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]))</span>

        <span class=k>for</span> <span class=n>state</span><span class=p>,</span> <span class=n>ax</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>axes</span><span class=p>):</span>
            <span class=n>ax</span><span class=o>.</span><span class=n>fill_between</span><span class=p>(</span><span class=n>xvals</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>T</span><span class=p>[:,</span> <span class=n>state</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=n>fillcolor</span><span class=p>)</span>
            <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>xvals</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>T</span><span class=p>[:,</span> <span class=n>state</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=n>ec</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=n>lw</span><span class=p>)</span>
            <span class=k>if</span> <span class=n>state</span> <span class=o>+</span> <span class=mi>1</span> <span class=ow>in</span> <span class=n>labelstates</span><span class=p>:</span>
                <span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>state</span> <span class=o>+</span> <span class=mi>1</span><span class=p>),</span> <span class=n>rotation</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>y</span><span class=o>=-</span><span class=mf>0.1</span><span class=p>)</span>
            <span class=n>ax</span><span class=o>.</span><span class=n>set_xticklabels</span><span class=p>([])</span>
            <span class=n>ax</span><span class=o>.</span><span class=n>set_yticklabels</span><span class=p>([])</span>
            <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s2>&quot;right&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
            <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s2>&quot;top&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
            <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s2>&quot;bottom&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
            <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s2>&quot;left&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
            <span class=n>plotting</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>no_yticks</span><span class=p>(</span><span class=n>ax</span><span class=p>)</span>
            <span class=n>plotting</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>no_xticks</span><span class=p>(</span><span class=n>ax</span><span class=p>)</span>
        <span class=c1># fig.suptitle(&#39;normalized place fields sorted by peak location (left) and mean location (right)&#39;, y=0.92, fontsize=14)</span>
        <span class=c1># ax.set_xticklabels([&#39;0&#39;,&#39;20&#39;, &#39;40&#39;, &#39;60&#39;, &#39;80&#39;, &#39;100&#39;])</span>
        <span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s2>&quot;external variable&quot;</span><span class=p>)</span>
        <span class=n>fig</span><span class=o>.</span><span class=n>text</span><span class=p>(</span>
            <span class=mf>0.02</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=s2>&quot;normalized state distribution&quot;</span><span class=p>,</span> <span class=n>va</span><span class=o>=</span><span class=s2>&quot;center&quot;</span><span class=p>,</span> <span class=n>rotation</span><span class=o>=</span><span class=s2>&quot;vertical&quot;</span>
        <span class=p>)</span>

        <span class=k>return</span> <span class=n>fig</span><span class=p>,</span> <span class=n>ax</span>

    <span class=k>def</span><span class=w> </span><span class=nf>estimate_model_quality</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>bst</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>n_shuffles</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>k_folds</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Estimate the HMM &#39;model quality&#39; associated with the set of events in bst.</span>

<span class=sd>        TODO: finish docstring, and do some more consistency checking...</span>

<span class=sd>        Params</span>
<span class=sd>        ======</span>

<span class=sd>        Returns</span>
<span class=sd>        =======</span>

<span class=sd>        quality :</span>
<span class=sd>        scores :</span>
<span class=sd>        shuffled :</span>

<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>n_states</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_components</span>
        <span class=n>quality</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>shuffles</span> <span class=o>=</span> <span class=n>estimate_model_quality</span><span class=p>(</span>
            <span class=n>bst</span><span class=o>=</span><span class=n>bst</span><span class=p>,</span>
            <span class=n>n_states</span><span class=o>=</span><span class=n>n_states</span><span class=p>,</span>
            <span class=n>n_shuffles</span><span class=o>=</span><span class=n>n_shuffles</span><span class=p>,</span>
            <span class=n>k_folds</span><span class=o>=</span><span class=n>k_folds</span><span class=p>,</span>
            <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
        <span class=p>)</span>

        <span class=k>return</span> <span class=n>quality</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>shuffles</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-attribute"> <h3 id=nelpy.hmmutils.PoissonHMM.extern_ class="doc doc-heading"> <code class="highlight language-python"><span class=n>extern_</span></code> <span class="doc doc-labels"> <small class="doc doc-label doc-label-property"><code>property</code></small> </span> </h3> <div class="doc doc-contents "> <p>Mapping from states to external variables (e.g., position).</p> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>Array of shape (n_components, n_extern) containing the mapping from states to external variables. Returns None if no mapping has been learned yet.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>hmm</span><span class=o>.</span><span class=n>fit_ext</span><span class=p>(</span><span class=n>bst</span><span class=p>,</span> <span class=n>position_data</span><span class=p>)</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>extern_map</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>extern_</span>
<span class=gp>&gt;&gt;&gt; </span><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;State 0 maps to position bin </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>extern_map</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> </div> </div> <div class="doc doc-object doc-attribute"> <h3 id=nelpy.hmmutils.PoissonHMM.means class="doc doc-heading"> <code class="highlight language-python"><span class=n>means</span></code> <span class="doc doc-labels"> <small class="doc doc-label doc-label-property"><code>property</code></small> </span> </h3> <div class="doc doc-contents "> <p>Observation matrix (mean firing rates for each state and unit).</p> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Array of shape (n_components, n_units) containing the mean parameters for each state.</p> </div> </td> </tr> </tbody> </table> </div> </div> <div class="doc doc-object doc-attribute"> <h3 id=nelpy.hmmutils.PoissonHMM.startprob class="doc doc-heading"> <code class="highlight language-python"><span class=n>startprob</span></code> <span class="doc doc-labels"> <small class="doc doc-label doc-label-property"><code>property</code></small> </span> </h3> <div class="doc doc-contents "> <p>Prior distribution over states.</p> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Array of shape (n_components,) representing the initial state probabilities.</p> </div> </td> </tr> </tbody> </table> </div> </div> <div class="doc doc-object doc-attribute"> <h3 id=nelpy.hmmutils.PoissonHMM.transmat class="doc doc-heading"> <code class="highlight language-python"><span class=n>transmat</span></code> <span class="doc doc-labels"> <small class="doc doc-label doc-label-property"><code>property</code></small> </span> </h3> <div class="doc doc-contents "> <p>Transition probability matrix.</p> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Array of shape (n_components, n_components) where A[i, j] = Pr(S_{t+1}=j | S_t=i).</p> </div> </td> </tr> </tbody> </table> </div> </div> <div class="doc doc-object doc-attribute"> <h3 id=nelpy.hmmutils.PoissonHMM.unit_ids class="doc doc-heading"> <code class="highlight language-python"><span class=n>unit_ids</span></code> <span class="doc doc-labels"> <small class="doc doc-label doc-label-property"><code>property</code></small> </span> </h3> <div class="doc doc-contents "> <p>List of unit IDs associated with the model.</p> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code><span title=list>list</span></code> </td> <td> <div class=doc-md-description> <p>List of unit IDs.</p> </div> </td> </tr> </tbody> </table> </div> </div> <div class="doc doc-object doc-attribute"> <h3 id=nelpy.hmmutils.PoissonHMM.unit_labels class="doc doc-heading"> <code class="highlight language-python"><span class=n>unit_labels</span></code> <span class="doc doc-labels"> <small class="doc doc-label doc-label-property"><code>property</code></small> </span> </h3> <div class="doc doc-contents "> <p>List of unit labels associated with the model.</p> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code><span title=list>list</span></code> </td> <td> <div class=doc-md-description> <p>List of unit labels.</p> </div> </td> </tr> </tbody> </table> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.assume_attributes class="doc doc-heading"> <code class="highlight language-python"><span class=n>assume_attributes</span><span class=p>(</span><span class=n>binnedSpikeTrainArray</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Assume subset of attributes from a BinnedSpikeTrainArray.</p> <p>This is used primarily to enable the sampling of sequences after a model has been fit.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>binnedSpikeTrainArray</code> </td> <td> <code><a class="autorefs autorefs-internal" href=../core/eventarray/#nelpy.core._eventarray.BinnedSpikeTrainArray>BinnedSpikeTrainArray</a></code> </td> <td> <div class=doc-md-description> <p>The BinnedSpikeTrainArray instance from which to copy attributes.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>519</span>
<span class=normal>520</span>
<span class=normal>521</span>
<span class=normal>522</span>
<span class=normal>523</span>
<span class=normal>524</span>
<span class=normal>525</span>
<span class=normal>526</span>
<span class=normal>527</span>
<span class=normal>528</span>
<span class=normal>529</span>
<span class=normal>530</span>
<span class=normal>531</span>
<span class=normal>532</span>
<span class=normal>533</span>
<span class=normal>534</span>
<span class=normal>535</span>
<span class=normal>536</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>assume_attributes</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>binnedSpikeTrainArray</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Assume subset of attributes from a BinnedSpikeTrainArray.</span>

<span class=sd>    This is used primarily to enable the sampling of sequences after a model has been fit.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    binnedSpikeTrainArray : BinnedSpikeTrainArray</span>
<span class=sd>        The BinnedSpikeTrainArray instance from which to copy attributes.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_ds</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>warn</span><span class=p>(</span><span class=s2>&quot;PoissonHMM(BinnedSpikeTrain) attributes already exist.&quot;</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>attrib</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>__attributes__</span><span class=p>:</span>
        <span class=n>exec</span><span class=p>(</span><span class=s2>&quot;self.&quot;</span> <span class=o>+</span> <span class=n>attrib</span> <span class=o>+</span> <span class=s2>&quot; = binnedSpikeTrainArray.&quot;</span> <span class=o>+</span> <span class=n>attrib</span><span class=p>)</span>
    <span class=bp>self</span><span class=o>.</span><span class=n>_unit_ids</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>binnedSpikeTrainArray</span><span class=o>.</span><span class=n>unit_ids</span><span class=p>)</span>
    <span class=bp>self</span><span class=o>.</span><span class=n>_unit_labels</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>binnedSpikeTrainArray</span><span class=o>.</span><span class=n>unit_labels</span><span class=p>)</span>
    <span class=bp>self</span><span class=o>.</span><span class=n>_unit_tags</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>binnedSpikeTrainArray</span><span class=o>.</span><span class=n>unit_tags</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.decode class="doc doc-heading"> <code class="highlight language-python"><span class=n>decode</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>algorithm</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Find the most likely state sequence corresponding to <code>X</code>.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>X</code> </td> <td> <code>array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</code> </td> <td> <div class=doc-md-description> <p>Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray. WARNING: Each decoding window is assumed to be similar in size to those used during training. If not, the tuning curves have to be scaled appropriately!</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>lengths</code> </td> <td> <code>array-like of int, shape (n_sequences,)</code> </td> <td> <div class=doc-md-description> <p>Lengths of the individual sequences in <code>X</code>. The sum of these should be <code>n_samples</code>. Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>w</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>algorithm</code> </td> <td> <code><span title=str>str</span></code> </td> <td> <div class=doc-md-description> <p>Decoder algorithm to be used (see DECODER_ALGORITHMS).</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>logprob</code></td> <td> <code>float or list of float</code> </td> <td> <div class=doc-md-description> <p>Log probability of the produced state sequence.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>state_sequence</code></td> <td> <code>np.ndarray or list of np.ndarray</code> </td> <td> <div class=doc-md-description> <p>Labels for each sample from <code>X</code> obtained via the given decoder algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>centers</code></td> <td> <code>np.ndarray or list of np.ndarray</code> </td> <td> <div class=doc-md-description> <p>Time-centers of all bins contained in <code>X</code>.</p> </div> </td> </tr> </tbody> </table> <details class=see-also open> <summary>See Also</summary> <p>score_samples : Compute the log probability under the model and posteriors. score : Compute the log probability under the model.</p> </details> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>logprob</span><span class=p>,</span> <span class=n>state_seq</span><span class=p>,</span> <span class=n>centers</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>bst</span><span class=p>)</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>logprob</span><span class=p>,</span> <span class=n>state_seq</span><span class=p>,</span> <span class=n>centers</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>algorithm</span><span class=o>=</span><span class=s2>&quot;viterbi&quot;</span><span class=p>)</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>662</span>
<span class=normal>663</span>
<span class=normal>664</span>
<span class=normal>665</span>
<span class=normal>666</span>
<span class=normal>667</span>
<span class=normal>668</span>
<span class=normal>669</span>
<span class=normal>670</span>
<span class=normal>671</span>
<span class=normal>672</span>
<span class=normal>673</span>
<span class=normal>674</span>
<span class=normal>675</span>
<span class=normal>676</span>
<span class=normal>677</span>
<span class=normal>678</span>
<span class=normal>679</span>
<span class=normal>680</span>
<span class=normal>681</span>
<span class=normal>682</span>
<span class=normal>683</span>
<span class=normal>684</span>
<span class=normal>685</span>
<span class=normal>686</span>
<span class=normal>687</span>
<span class=normal>688</span>
<span class=normal>689</span>
<span class=normal>690</span>
<span class=normal>691</span>
<span class=normal>692</span>
<span class=normal>693</span>
<span class=normal>694</span>
<span class=normal>695</span>
<span class=normal>696</span>
<span class=normal>697</span>
<span class=normal>698</span>
<span class=normal>699</span>
<span class=normal>700</span>
<span class=normal>701</span>
<span class=normal>702</span>
<span class=normal>703</span>
<span class=normal>704</span>
<span class=normal>705</span>
<span class=normal>706</span>
<span class=normal>707</span>
<span class=normal>708</span>
<span class=normal>709</span>
<span class=normal>710</span>
<span class=normal>711</span>
<span class=normal>712</span>
<span class=normal>713</span>
<span class=normal>714</span>
<span class=normal>715</span>
<span class=normal>716</span>
<span class=normal>717</span>
<span class=normal>718</span>
<span class=normal>719</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>algorithm</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Find the most likely state sequence corresponding to ``X``.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    X : array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>        Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>        WARNING: Each decoding window is assumed to be similar in size to those used during training.</span>
<span class=sd>        If not, the tuning curves have to be scaled appropriately!</span>
<span class=sd>    lengths : array-like of int, shape (n_sequences,), optional</span>
<span class=sd>        Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>        Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>
<span class=sd>    w : int, optional</span>
<span class=sd>        Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</span>
<span class=sd>    algorithm : str, optional</span>
<span class=sd>        Decoder algorithm to be used (see DECODER_ALGORITHMS).</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    logprob : float or list of float</span>
<span class=sd>        Log probability of the produced state sequence.</span>
<span class=sd>    state_sequence : np.ndarray or list of np.ndarray</span>
<span class=sd>        Labels for each sample from ``X`` obtained via the given decoder algorithm.</span>
<span class=sd>    centers : np.ndarray or list of np.ndarray</span>
<span class=sd>        Time-centers of all bins contained in ``X``.</span>

<span class=sd>    See Also</span>
<span class=sd>    --------</span>
<span class=sd>    score_samples : Compute the log probability under the model and posteriors.</span>
<span class=sd>    score : Compute the log probability under the model.</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    &gt;&gt;&gt; logprob, state_seq, centers = hmm.decode(bst)</span>
<span class=sd>    &gt;&gt;&gt; logprob, state_seq, centers = hmm.decode(X, algorithm=&quot;viterbi&quot;)</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
        <span class=c1># assume we have a feature matrix</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
            <span class=p>)</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>algorithm</span><span class=o>=</span><span class=n>algorithm</span><span class=p>),</span> <span class=kc>None</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=c1># we have a BinnedSpikeTrainArray</span>
        <span class=n>logprobs</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=n>state_sequences</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=n>centers</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
            <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>seq</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
            <span class=n>logprob</span><span class=p>,</span> <span class=n>state_sequence</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_decode</span><span class=p>(</span>
                <span class=bp>self</span><span class=p>,</span> <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>algorithm</span><span class=o>=</span><span class=n>algorithm</span>
            <span class=p>)</span>
            <span class=n>logprobs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>logprob</span><span class=p>)</span>
            <span class=n>state_sequences</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>state_sequence</span><span class=p>)</span>
            <span class=n>centers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>seq</span><span class=o>.</span><span class=n>centers</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>logprobs</span><span class=p>,</span> <span class=n>state_sequences</span><span class=p>,</span> <span class=n>centers</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.decode_ext class="doc doc-heading"> <code class="highlight language-python"><span class=n>decode_ext</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>ext_shape</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Find memoryless most likely state sequence corresponding to <code>X</code>, (that is, the symbol-by-symbol MAP sequence) and then map those states to an associated external representation (e.g., position).</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>X</code> </td> <td> <code>(<span title=array>array</span> - <span title=like>like</span>, <span title=shape>shape</span>(<span title=n_samples>n_samples</span>, <span title=n_features>n_features</span>) or <a class="autorefs autorefs-internal" href=../core/eventarray/#nelpy.core._eventarray.BinnedSpikeTrainArray>BinnedSpikeTrainArray</a>)</code> </td> <td> <div class=doc-md-description> <p>Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>lengths</code> </td> <td> <code>array-like of integers, shape (n_sequences, )</code> </td> <td> <div class=doc-md-description> <p>Lengths of the individual sequences in <code>X</code>. The sum of these should be <code>n_samples</code>. Not used when X is a nelpy.BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>w</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>ext_shape</code> </td> <td> <code><span title=tuple>tuple</span></code> </td> <td> <div class=doc-md-description> <p>Shape of the external variables.</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>ext_posteriors</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Array of shape (n_extern, n_samples) with state-membership probabilities for each sample in <code>X</code>.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>bdries</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Array of bin boundaries.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>mode_pth</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Most likely external variable sequence (mode path).</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>mean_pth</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Mean external variable sequence (mean path).</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Examples:</span></p> <p>For 1D external variables:</p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>posterior_pos</span><span class=p>,</span> <span class=n>bdries</span><span class=p>,</span> <span class=n>mode_pth</span><span class=p>,</span> <span class=n>mean_pth</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>decode_ext</span><span class=p>(</span>
<span class=gp>... </span>    <span class=n>bst_no_ripple</span><span class=p>,</span> <span class=n>ext_shape</span><span class=o>=</span><span class=p>(</span><span class=n>vtc</span><span class=o>.</span><span class=n>n_bins</span><span class=p>,)</span>
<span class=gp>... </span><span class=p>)</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>mean_pth</span> <span class=o>=</span> <span class=n>vtc</span><span class=o>.</span><span class=n>bins</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>mean_pth</span> <span class=o>*</span> <span class=p>(</span><span class=n>vtc</span><span class=o>.</span><span class=n>bins</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=n>vtc</span><span class=o>.</span><span class=n>bins</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</code></pre></div> <p>For 2D external variables:</p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>posterior_</span><span class=p>,</span> <span class=n>bdries_</span><span class=p>,</span> <span class=n>mode_pth_</span><span class=p>,</span> <span class=n>mean_pth_</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>decode_ext</span><span class=p>(</span>
<span class=gp>... </span>    <span class=n>bst</span><span class=p>,</span> <span class=n>ext_shape</span><span class=o>=</span><span class=p>(</span><span class=n>ext_nx</span><span class=p>,</span> <span class=n>ext_ny</span><span class=p>)</span>
<span class=gp>... </span><span class=p>)</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>mean_pth_</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:]</span> <span class=o>=</span> <span class=n>vtc2d</span><span class=o>.</span><span class=n>xbins</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>mean_pth_</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:]</span> <span class=o>*</span> <span class=p>(</span>
<span class=gp>... </span>    <span class=n>vtc2d</span><span class=o>.</span><span class=n>xbins</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=n>vtc2d</span><span class=o>.</span><span class=n>xbins</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
<span class=gp>... </span><span class=p>)</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>mean_pth_</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span> <span class=o>=</span> <span class=n>vtc2d</span><span class=o>.</span><span class=n>ybins</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=n>mean_pth_</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span> <span class=o>*</span> <span class=p>(</span>
<span class=gp>... </span>    <span class=n>vtc2d</span><span class=o>.</span><span class=n>ybins</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=n>vtc2d</span><span class=o>.</span><span class=n>ybins</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
<span class=gp>... </span><span class=p>)</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1204</span>
<span class=normal>1205</span>
<span class=normal>1206</span>
<span class=normal>1207</span>
<span class=normal>1208</span>
<span class=normal>1209</span>
<span class=normal>1210</span>
<span class=normal>1211</span>
<span class=normal>1212</span>
<span class=normal>1213</span>
<span class=normal>1214</span>
<span class=normal>1215</span>
<span class=normal>1216</span>
<span class=normal>1217</span>
<span class=normal>1218</span>
<span class=normal>1219</span>
<span class=normal>1220</span>
<span class=normal>1221</span>
<span class=normal>1222</span>
<span class=normal>1223</span>
<span class=normal>1224</span>
<span class=normal>1225</span>
<span class=normal>1226</span>
<span class=normal>1227</span>
<span class=normal>1228</span>
<span class=normal>1229</span>
<span class=normal>1230</span>
<span class=normal>1231</span>
<span class=normal>1232</span>
<span class=normal>1233</span>
<span class=normal>1234</span>
<span class=normal>1235</span>
<span class=normal>1236</span>
<span class=normal>1237</span>
<span class=normal>1238</span>
<span class=normal>1239</span>
<span class=normal>1240</span>
<span class=normal>1241</span>
<span class=normal>1242</span>
<span class=normal>1243</span>
<span class=normal>1244</span>
<span class=normal>1245</span>
<span class=normal>1246</span>
<span class=normal>1247</span>
<span class=normal>1248</span>
<span class=normal>1249</span>
<span class=normal>1250</span>
<span class=normal>1251</span>
<span class=normal>1252</span>
<span class=normal>1253</span>
<span class=normal>1254</span>
<span class=normal>1255</span>
<span class=normal>1256</span>
<span class=normal>1257</span>
<span class=normal>1258</span>
<span class=normal>1259</span>
<span class=normal>1260</span>
<span class=normal>1261</span>
<span class=normal>1262</span>
<span class=normal>1263</span>
<span class=normal>1264</span>
<span class=normal>1265</span>
<span class=normal>1266</span>
<span class=normal>1267</span>
<span class=normal>1268</span>
<span class=normal>1269</span>
<span class=normal>1270</span>
<span class=normal>1271</span>
<span class=normal>1272</span>
<span class=normal>1273</span>
<span class=normal>1274</span>
<span class=normal>1275</span>
<span class=normal>1276</span>
<span class=normal>1277</span>
<span class=normal>1278</span>
<span class=normal>1279</span>
<span class=normal>1280</span>
<span class=normal>1281</span>
<span class=normal>1282</span>
<span class=normal>1283</span>
<span class=normal>1284</span>
<span class=normal>1285</span>
<span class=normal>1286</span>
<span class=normal>1287</span>
<span class=normal>1288</span>
<span class=normal>1289</span>
<span class=normal>1290</span>
<span class=normal>1291</span>
<span class=normal>1292</span>
<span class=normal>1293</span>
<span class=normal>1294</span>
<span class=normal>1295</span>
<span class=normal>1296</span>
<span class=normal>1297</span>
<span class=normal>1298</span>
<span class=normal>1299</span>
<span class=normal>1300</span>
<span class=normal>1301</span>
<span class=normal>1302</span>
<span class=normal>1303</span>
<span class=normal>1304</span>
<span class=normal>1305</span>
<span class=normal>1306</span>
<span class=normal>1307</span>
<span class=normal>1308</span>
<span class=normal>1309</span>
<span class=normal>1310</span>
<span class=normal>1311</span>
<span class=normal>1312</span>
<span class=normal>1313</span>
<span class=normal>1314</span>
<span class=normal>1315</span>
<span class=normal>1316</span>
<span class=normal>1317</span>
<span class=normal>1318</span>
<span class=normal>1319</span>
<span class=normal>1320</span>
<span class=normal>1321</span>
<span class=normal>1322</span>
<span class=normal>1323</span>
<span class=normal>1324</span>
<span class=normal>1325</span>
<span class=normal>1326</span>
<span class=normal>1327</span>
<span class=normal>1328</span>
<span class=normal>1329</span>
<span class=normal>1330</span>
<span class=normal>1331</span>
<span class=normal>1332</span>
<span class=normal>1333</span>
<span class=normal>1334</span>
<span class=normal>1335</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>decode_ext</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>ext_shape</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Find memoryless most likely state sequence corresponding to ``X``,</span>
<span class=sd>    (that is, the symbol-by-symbol MAP sequence) and then map those</span>
<span class=sd>    states to an associated external representation (e.g., position).</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    X : array-like, shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>        Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>    lengths : array-like of integers, shape (n_sequences, ), optional</span>
<span class=sd>        Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>        Not used when X is a nelpy.BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>
<span class=sd>    w : int, optional</span>
<span class=sd>        Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</span>
<span class=sd>    ext_shape : tuple, optional</span>
<span class=sd>        Shape of the external variables.</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    ext_posteriors : np.ndarray</span>
<span class=sd>        Array of shape (n_extern, n_samples) with state-membership probabilities for each sample in ``X``.</span>
<span class=sd>    bdries : np.ndarray</span>
<span class=sd>        Array of bin boundaries.</span>
<span class=sd>    mode_pth : np.ndarray</span>
<span class=sd>        Most likely external variable sequence (mode path).</span>
<span class=sd>    mean_pth : np.ndarray</span>
<span class=sd>        Mean external variable sequence (mean path).</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    For 1D external variables:</span>
<span class=sd>    &gt;&gt;&gt; posterior_pos, bdries, mode_pth, mean_pth = hmm.decode_ext(</span>
<span class=sd>    ...     bst_no_ripple, ext_shape=(vtc.n_bins,)</span>
<span class=sd>    ... )</span>
<span class=sd>    &gt;&gt;&gt; mean_pth = vtc.bins[0] + mean_pth * (vtc.bins[-1] - vtc.bins[0])</span>

<span class=sd>    For 2D external variables:</span>
<span class=sd>    &gt;&gt;&gt; posterior_, bdries_, mode_pth_, mean_pth_ = hmm.decode_ext(</span>
<span class=sd>    ...     bst, ext_shape=(ext_nx, ext_ny)</span>
<span class=sd>    ... )</span>
<span class=sd>    &gt;&gt;&gt; mean_pth_[0, :] = vtc2d.xbins[0] + mean_pth_[0, :] * (</span>
<span class=sd>    ...     vtc2d.xbins[-1] - vtc2d.xbins[0]</span>
<span class=sd>    ... )</span>
<span class=sd>    &gt;&gt;&gt; mean_pth_[1, :] = vtc2d.ybins[0] + mean_pth_[1, :] * (</span>
<span class=sd>    ...     vtc2d.ybins[-1] - vtc2d.ybins[0]</span>
<span class=sd>    ... )</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=n>_</span><span class=p>,</span> <span class=n>n_extern</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>shape</span>

    <span class=k>if</span> <span class=n>ext_shape</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>ext_shape</span> <span class=o>=</span> <span class=n>n_extern</span>

    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
        <span class=c1># assume we have a feature matrix</span>
        <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;not implemented yet.&quot;</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
            <span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=c1># we have a BinnedSpikeTrainArray</span>
        <span class=k>pass</span>
    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>ext_shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
        <span class=c1># do old style decoding</span>
        <span class=c1># TODO: this can be improved to be like the 2D case!</span>
        <span class=n>state_posteriors</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span>
            <span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>,</span> <span class=n>returnLengths</span><span class=o>=</span><span class=kc>True</span>
        <span class=p>)</span>
        <span class=c1># fixy = np.mean(self._extern_ * np.arange(n_extern), axis=1)</span>
        <span class=c1># mean_pth = np.sum(state_posteriors.T*fixy, axis=1) # range 0 to 1</span>
        <span class=n>ext_posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span>
            <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n_extern</span><span class=p>))</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>state_posteriors</span>
        <span class=p>)</span>
        <span class=c1># normalize ext_posterior distributions:</span>
        <span class=n>ext_posteriors</span> <span class=o>=</span> <span class=n>ext_posteriors</span> <span class=o>/</span> <span class=n>ext_posteriors</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
        <span class=n>mean_pth</span> <span class=o>=</span> <span class=p>(</span>
            <span class=n>ext_posteriors</span><span class=o>.</span><span class=n>T</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>atleast_2d</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n_extern</span><span class=p>))</span>
        <span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
        <span class=n>mode_pth</span> <span class=o>=</span> <span class=p>(</span>
            <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>ext_posteriors</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span> <span class=o>/</span> <span class=n>n_extern</span>
        <span class=p>)</span>  <span class=c1># range 0 to n_extern</span>

    <span class=k>elif</span> <span class=nb>len</span><span class=p>(</span><span class=n>ext_shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>
        <span class=n>ext_posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>ext_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>X</span><span class=o>.</span><span class=n>n_bins</span><span class=p>))</span>
        <span class=c1># get posterior distribution over states, of size (num_States, n_extern)</span>
        <span class=n>state_posteriors</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span>
            <span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>,</span> <span class=n>returnLengths</span><span class=o>=</span><span class=kc>True</span>
        <span class=p>)</span>
        <span class=c1># for each bin, compute the distribution in the external domain</span>
        <span class=k>for</span> <span class=n>bb</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>n_bins</span><span class=p>):</span>
            <span class=n>ext_posteriors</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>bb</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span>
                <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=o>*</span> <span class=n>state_posteriors</span><span class=p>[:,</span> <span class=p>[</span><span class=n>bb</span><span class=p>]])</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>),</span> <span class=n>ext_shape</span>
            <span class=p>)</span>
        <span class=c1># now compute mean and mode paths</span>
        <span class=n>expected_x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span>
            <span class=p>(</span>
                <span class=n>ext_posteriors</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
                <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>atleast_2d</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span><span class=o>.</span><span class=n>T</span>
            <span class=p>),</span>
            <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
        <span class=p>)</span>
        <span class=n>expected_y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span>
            <span class=p>(</span>
                <span class=n>ext_posteriors</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
                <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>atleast_2d</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]))</span><span class=o>.</span><span class=n>T</span>
            <span class=p>),</span>
            <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
        <span class=p>)</span>
        <span class=n>mean_pth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>vstack</span><span class=p>((</span><span class=n>expected_x</span><span class=p>,</span> <span class=n>expected_y</span><span class=p>))</span>

        <span class=n>mode_pth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>n_bins</span><span class=p>))</span>
        <span class=k>for</span> <span class=n>tt</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>n_bins</span><span class=p>):</span>
            <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>any</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>ext_posteriors</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>tt</span><span class=p>])):</span>
                <span class=n>mode_pth</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>tt</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
                <span class=n>mode_pth</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>tt</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>x_</span><span class=p>,</span> <span class=n>y_</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>unravel_index</span><span class=p>(</span>
                    <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>ext_posteriors</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>tt</span><span class=p>]),</span>
                    <span class=p>(</span><span class=n>ext_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]),</span>
                <span class=p>)</span>
                <span class=n>mode_pth</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>tt</span><span class=p>]</span> <span class=o>=</span> <span class=n>x_</span> <span class=o>/</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
                <span class=n>mode_pth</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=n>tt</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_</span> <span class=o>/</span> <span class=n>ext_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>

        <span class=n>ext_posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>ext_posteriors</span><span class=p>,</span> <span class=n>axes</span><span class=o>=</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=k>raise</span> <span class=ne>TypeError</span><span class=p>(</span><span class=s2>&quot;shape not currently supported!&quot;</span><span class=p>)</span>

    <span class=n>bdries</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>lengths</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>ext_posteriors</span><span class=p>,</span> <span class=n>bdries</span><span class=p>,</span> <span class=n>mode_pth</span><span class=p>,</span> <span class=n>mean_pth</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.estimate_model_quality class="doc doc-heading"> <code class="highlight language-python"><span class=n>estimate_model_quality</span><span class=p>(</span><span class=n>bst</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>n_shuffles</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>k_folds</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Estimate the HMM 'model quality' associated with the set of events in bst.</p> <p>TODO: finish docstring, and do some more consistency checking...</p> <h4 id=nelpy.hmmutils.PoissonHMM.estimate_model_quality--params>Params</h4> <h4 id=nelpy.hmmutils.PoissonHMM.estimate_model_quality--returns>Returns</h4> <p>quality : scores : shuffled :</p> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1388</span>
<span class=normal>1389</span>
<span class=normal>1390</span>
<span class=normal>1391</span>
<span class=normal>1392</span>
<span class=normal>1393</span>
<span class=normal>1394</span>
<span class=normal>1395</span>
<span class=normal>1396</span>
<span class=normal>1397</span>
<span class=normal>1398</span>
<span class=normal>1399</span>
<span class=normal>1400</span>
<span class=normal>1401</span>
<span class=normal>1402</span>
<span class=normal>1403</span>
<span class=normal>1404</span>
<span class=normal>1405</span>
<span class=normal>1406</span>
<span class=normal>1407</span>
<span class=normal>1408</span>
<span class=normal>1409</span>
<span class=normal>1410</span>
<span class=normal>1411</span>
<span class=normal>1412</span>
<span class=normal>1413</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>estimate_model_quality</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>bst</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>n_shuffles</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>k_folds</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Estimate the HMM &#39;model quality&#39; associated with the set of events in bst.</span>

<span class=sd>    TODO: finish docstring, and do some more consistency checking...</span>

<span class=sd>    Params</span>
<span class=sd>    ======</span>

<span class=sd>    Returns</span>
<span class=sd>    =======</span>

<span class=sd>    quality :</span>
<span class=sd>    scores :</span>
<span class=sd>    shuffled :</span>

<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>n_states</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_components</span>
    <span class=n>quality</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>shuffles</span> <span class=o>=</span> <span class=n>estimate_model_quality</span><span class=p>(</span>
        <span class=n>bst</span><span class=o>=</span><span class=n>bst</span><span class=p>,</span>
        <span class=n>n_states</span><span class=o>=</span><span class=n>n_states</span><span class=p>,</span>
        <span class=n>n_shuffles</span><span class=o>=</span><span class=n>n_shuffles</span><span class=p>,</span>
        <span class=n>k_folds</span><span class=o>=</span><span class=n>k_folds</span><span class=p>,</span>
        <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
    <span class=p>)</span>

    <span class=k>return</span> <span class=n>quality</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>shuffles</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.fit class="doc doc-heading"> <code class="highlight language-python"><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Estimate model parameters using nelpy objects.</p> <p>An initialization step is performed before entering the EM-algorithm. If you want to avoid this step for a subset of the parameters, pass proper <code>init_params</code> keyword argument to estimator's constructor.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>X</code> </td> <td> <code>(<span title=array>array</span> - <span title=like>like</span>, <span title=shape>shape</span>(<span title=n_samples>n_samples</span>, <span title=n_units>n_units</span>))</code> </td> <td> <div class=doc-md-description> <p>Feature matrix of individual samples. OR nelpy.BinnedSpikeTrainArray</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>lengths</code> </td> <td> <code>array-like of integers, shape (n_sequences, )</code> </td> <td> <div class=doc-md-description> <p>Lengths of the individual sequences in <code>X</code>. The sum of these should be <code>n_samples</code>. This is not used when X is a nelpy.BinnedSpikeTrainArray, in which case the lenghts are automatically inferred.</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>self</code></td> <td> <code><span title=object>object</span></code> </td> <td> <div class=doc-md-description> <p>Returns self.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 995</span>
<span class=normal> 996</span>
<span class=normal> 997</span>
<span class=normal> 998</span>
<span class=normal> 999</span>
<span class=normal>1000</span>
<span class=normal>1001</span>
<span class=normal>1002</span>
<span class=normal>1003</span>
<span class=normal>1004</span>
<span class=normal>1005</span>
<span class=normal>1006</span>
<span class=normal>1007</span>
<span class=normal>1008</span>
<span class=normal>1009</span>
<span class=normal>1010</span>
<span class=normal>1011</span>
<span class=normal>1012</span>
<span class=normal>1013</span>
<span class=normal>1014</span>
<span class=normal>1015</span>
<span class=normal>1016</span>
<span class=normal>1017</span>
<span class=normal>1018</span>
<span class=normal>1019</span>
<span class=normal>1020</span>
<span class=normal>1021</span>
<span class=normal>1022</span>
<span class=normal>1023</span>
<span class=normal>1024</span>
<span class=normal>1025</span>
<span class=normal>1026</span>
<span class=normal>1027</span>
<span class=normal>1028</span>
<span class=normal>1029</span>
<span class=normal>1030</span>
<span class=normal>1031</span>
<span class=normal>1032</span>
<span class=normal>1033</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Estimate model parameters using nelpy objects.</span>

<span class=sd>    An initialization step is performed before entering the</span>
<span class=sd>    EM-algorithm. If you want to avoid this step for a subset of</span>
<span class=sd>    the parameters, pass proper ``init_params`` keyword argument</span>
<span class=sd>    to estimator&#39;s constructor.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    X : array-like, shape (n_samples, n_units)</span>
<span class=sd>        Feature matrix of individual samples.</span>
<span class=sd>        OR</span>
<span class=sd>        nelpy.BinnedSpikeTrainArray</span>
<span class=sd>    lengths : array-like of integers, shape (n_sequences, )</span>
<span class=sd>        Lengths of the individual sequences in ``X``. The sum of</span>
<span class=sd>        these should be ``n_samples``. This is not used when X is</span>
<span class=sd>        a nelpy.BinnedSpikeTrainArray, in which case the lenghts are</span>
<span class=sd>        automatically inferred.</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    self : object</span>
<span class=sd>        Returns self.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
        <span class=c1># assume we have a feature matrix</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
            <span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=c1># we have a BinnedSpikeTrainArray</span>
        <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
        <span class=c1># adopt unit_ids, unit_labels, etc. from BinnedSpikeTrain</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>assume_attributes</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
    <span class=k>return</span> <span class=bp>self</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.fit_ext class="doc doc-heading"> <code class="highlight language-python"><span class=n>fit_ext</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>ext</span><span class=p>,</span> <span class=n>n_extern</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>save</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>normalize</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>normalize_by_occupancy</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Learn a mapping from the internal state space, to an external augmented space (e.g. position).</p> <p>Returns a row-normalized version of (n_states, n_ext), that is, a distribution over external bins for each state.</p> <p>X : BinnedSpikeTrainArray</p> <p>ext : array-like array of external correlates (n_bins, ) n_extern : int number of extern variables, with range 0,.. n_extern-1 save : bool stores extern in PoissonHMM if true, discards it if not w: normalize : bool If True, then normalize each state to have a distribution over ext. occupancy : array of bin counts Default is all ones (uniform).</p> <p>self.extern_ of size (n_components, n_extern)</p> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1035</span>
<span class=normal>1036</span>
<span class=normal>1037</span>
<span class=normal>1038</span>
<span class=normal>1039</span>
<span class=normal>1040</span>
<span class=normal>1041</span>
<span class=normal>1042</span>
<span class=normal>1043</span>
<span class=normal>1044</span>
<span class=normal>1045</span>
<span class=normal>1046</span>
<span class=normal>1047</span>
<span class=normal>1048</span>
<span class=normal>1049</span>
<span class=normal>1050</span>
<span class=normal>1051</span>
<span class=normal>1052</span>
<span class=normal>1053</span>
<span class=normal>1054</span>
<span class=normal>1055</span>
<span class=normal>1056</span>
<span class=normal>1057</span>
<span class=normal>1058</span>
<span class=normal>1059</span>
<span class=normal>1060</span>
<span class=normal>1061</span>
<span class=normal>1062</span>
<span class=normal>1063</span>
<span class=normal>1064</span>
<span class=normal>1065</span>
<span class=normal>1066</span>
<span class=normal>1067</span>
<span class=normal>1068</span>
<span class=normal>1069</span>
<span class=normal>1070</span>
<span class=normal>1071</span>
<span class=normal>1072</span>
<span class=normal>1073</span>
<span class=normal>1074</span>
<span class=normal>1075</span>
<span class=normal>1076</span>
<span class=normal>1077</span>
<span class=normal>1078</span>
<span class=normal>1079</span>
<span class=normal>1080</span>
<span class=normal>1081</span>
<span class=normal>1082</span>
<span class=normal>1083</span>
<span class=normal>1084</span>
<span class=normal>1085</span>
<span class=normal>1086</span>
<span class=normal>1087</span>
<span class=normal>1088</span>
<span class=normal>1089</span>
<span class=normal>1090</span>
<span class=normal>1091</span>
<span class=normal>1092</span>
<span class=normal>1093</span>
<span class=normal>1094</span>
<span class=normal>1095</span>
<span class=normal>1096</span>
<span class=normal>1097</span>
<span class=normal>1098</span>
<span class=normal>1099</span>
<span class=normal>1100</span>
<span class=normal>1101</span>
<span class=normal>1102</span>
<span class=normal>1103</span>
<span class=normal>1104</span>
<span class=normal>1105</span>
<span class=normal>1106</span>
<span class=normal>1107</span>
<span class=normal>1108</span>
<span class=normal>1109</span>
<span class=normal>1110</span>
<span class=normal>1111</span>
<span class=normal>1112</span>
<span class=normal>1113</span>
<span class=normal>1114</span>
<span class=normal>1115</span>
<span class=normal>1116</span>
<span class=normal>1117</span>
<span class=normal>1118</span>
<span class=normal>1119</span>
<span class=normal>1120</span>
<span class=normal>1121</span>
<span class=normal>1122</span>
<span class=normal>1123</span>
<span class=normal>1124</span>
<span class=normal>1125</span>
<span class=normal>1126</span>
<span class=normal>1127</span>
<span class=normal>1128</span>
<span class=normal>1129</span>
<span class=normal>1130</span>
<span class=normal>1131</span>
<span class=normal>1132</span>
<span class=normal>1133</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>fit_ext</span><span class=p>(</span>
    <span class=bp>self</span><span class=p>,</span>
    <span class=n>X</span><span class=p>,</span>
    <span class=n>ext</span><span class=p>,</span>
    <span class=n>n_extern</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
    <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
    <span class=n>save</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
    <span class=n>normalize</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>normalize_by_occupancy</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Learn a mapping from the internal state space, to an external</span>
<span class=sd>    augmented space (e.g. position).</span>

<span class=sd>    Returns a row-normalized version of (n_states, n_ext), that</span>
<span class=sd>    is, a distribution over external bins for each state.</span>

<span class=sd>    X : BinnedSpikeTrainArray</span>

<span class=sd>    ext : array-like</span>
<span class=sd>        array of external correlates (n_bins, )</span>
<span class=sd>    n_extern : int</span>
<span class=sd>        number of extern variables, with range 0,.. n_extern-1</span>
<span class=sd>    save : bool</span>
<span class=sd>        stores extern in PoissonHMM if true, discards it if not</span>
<span class=sd>    w:</span>
<span class=sd>    normalize : bool</span>
<span class=sd>        If True, then normalize each state to have a distribution over ext.</span>
<span class=sd>    occupancy : array of bin counts</span>
<span class=sd>        Default is all ones (uniform).</span>

<span class=sd>    self.extern_ of size (n_components, n_extern)</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>if</span> <span class=n>n_extern</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>n_extern</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>unique</span><span class=p>(</span><span class=n>ext</span><span class=p>))</span>
        <span class=n>ext_map</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n_extern</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>ele</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>unique</span><span class=p>(</span><span class=n>ext</span><span class=p>)):</span>
            <span class=n>ext_map</span><span class=p>[</span><span class=n>ele</span><span class=p>]</span> <span class=o>=</span> <span class=n>ii</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>ext_map</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n_extern</span><span class=p>)</span>

    <span class=c1># idea: here, ext can be anything, and n_extern should be range</span>
    <span class=c1># we can e.g., define extern correlates {leftrun, rightrun} and</span>
    <span class=c1># fit the mapping. This is not expected to be good at all for</span>
    <span class=c1># most states, but it could allow us to identify a state or two</span>
    <span class=c1># for which there *might* be a strong predictive relationship.</span>
    <span class=c1># In this way, the binning, etc. should be done external to this</span>
    <span class=c1># function, but it might still make sense to encapsulate it as</span>
    <span class=c1># a helper function inside PoissonHMM?</span>

    <span class=c1># xpos, ypos = get_position(exp_data[&#39;session1&#39;][&#39;posdf&#39;], bst.centers)</span>
    <span class=c1># x0=0; xl=100; n_extern=50</span>
    <span class=c1># xx_left = np.linspace(x0,xl,n_extern+1)</span>
    <span class=c1># xx_mid = np.linspace(x0,xl,n_extern+1)[:-1]; xx_mid += (xx_mid[1]-xx_mid[0])/2</span>
    <span class=c1># ext = np.digitize(xpos, xx_left) - 1 # spatial bin numbers</span>

    <span class=n>extern</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=n>n_extern</span><span class=p>))</span>

    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
        <span class=c1># assume we have a feature matrix</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
            <span class=p>)</span>
        <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=c1># we have a BinnedSpikeTrainArray</span>
        <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>

    <span class=n>posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>vstack</span><span class=p>(</span><span class=n>posteriors</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>  <span class=c1># 1D array of states, of length n_bins</span>

    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>posteriors</span><span class=p>)</span> <span class=o>!=</span> <span class=nb>len</span><span class=p>(</span><span class=n>ext</span><span class=p>):</span>
        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;ext must have same length as decoded state sequence!&quot;</span><span class=p>)</span>

    <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>posterior</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>posteriors</span><span class=p>):</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>np</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>ext</span><span class=p>[</span><span class=n>ii</span><span class=p>]):</span>
            <span class=n>extern</span><span class=p>[:,</span> <span class=n>ext_map</span><span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=n>ext</span><span class=p>[</span><span class=n>ii</span><span class=p>])]]</span> <span class=o>+=</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>posterior</span><span class=p>)</span>

    <span class=k>if</span> <span class=n>normalize_by_occupancy</span><span class=p>:</span>
        <span class=n>occupancy</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>ext</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=n>n_extern</span><span class=p>,</span> <span class=nb>range</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_extern</span><span class=p>])</span>
        <span class=n>occupancy</span><span class=p>[</span><span class=n>occupancy</span> <span class=o>==</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
        <span class=n>occupancy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>atleast_2d</span><span class=p>(</span><span class=n>occupancy</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>occupancy</span> <span class=o>=</span> <span class=mi>1</span>

    <span class=n>extern</span> <span class=o>=</span> <span class=n>extern</span> <span class=o>/</span> <span class=n>occupancy</span>

    <span class=k>if</span> <span class=n>normalize</span><span class=p>:</span>
        <span class=c1># normalize extern tuning curves:</span>
        <span class=n>rowsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>tile</span><span class=p>(</span><span class=n>extern</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=p>(</span><span class=n>n_extern</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>T</span>
        <span class=n>rowsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>rowsum</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=mi>1</span><span class=p>,</span> <span class=n>rowsum</span><span class=p>)</span>
        <span class=n>extern</span> <span class=o>=</span> <span class=n>extern</span> <span class=o>/</span> <span class=n>rowsum</span>

    <span class=k>if</span> <span class=n>save</span><span class=p>:</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=o>=</span> <span class=n>extern</span>
        <span class=c1># self._extern_map = ext_map</span>

    <span class=k>return</span> <span class=n>extern</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.fit_ext2 class="doc doc-heading"> <code class="highlight language-python"><span class=n>fit_ext2</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>ext</span><span class=p>,</span> <span class=n>n_extern</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Learn a mapping from the internal state space, to an external augmented space (e.g. position).</p> <p>Returns a column-normalized version of (n_states, n_ext), that is, a distribution over states for each extern bin.</p> <p>X : BinnedSpikeTrainArray</p> <p>ext : array-like array of external correlates (n_bins, ) n_extern : int number of extern variables, with range 0,.. n_extern-1</p> <p>save : bool stores extern in PoissonHMM if true, discards it if not</p> <p>self.extern_ of size (n_components, n_extern)</p> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1135</span>
<span class=normal>1136</span>
<span class=normal>1137</span>
<span class=normal>1138</span>
<span class=normal>1139</span>
<span class=normal>1140</span>
<span class=normal>1141</span>
<span class=normal>1142</span>
<span class=normal>1143</span>
<span class=normal>1144</span>
<span class=normal>1145</span>
<span class=normal>1146</span>
<span class=normal>1147</span>
<span class=normal>1148</span>
<span class=normal>1149</span>
<span class=normal>1150</span>
<span class=normal>1151</span>
<span class=normal>1152</span>
<span class=normal>1153</span>
<span class=normal>1154</span>
<span class=normal>1155</span>
<span class=normal>1156</span>
<span class=normal>1157</span>
<span class=normal>1158</span>
<span class=normal>1159</span>
<span class=normal>1160</span>
<span class=normal>1161</span>
<span class=normal>1162</span>
<span class=normal>1163</span>
<span class=normal>1164</span>
<span class=normal>1165</span>
<span class=normal>1166</span>
<span class=normal>1167</span>
<span class=normal>1168</span>
<span class=normal>1169</span>
<span class=normal>1170</span>
<span class=normal>1171</span>
<span class=normal>1172</span>
<span class=normal>1173</span>
<span class=normal>1174</span>
<span class=normal>1175</span>
<span class=normal>1176</span>
<span class=normal>1177</span>
<span class=normal>1178</span>
<span class=normal>1179</span>
<span class=normal>1180</span>
<span class=normal>1181</span>
<span class=normal>1182</span>
<span class=normal>1183</span>
<span class=normal>1184</span>
<span class=normal>1185</span>
<span class=normal>1186</span>
<span class=normal>1187</span>
<span class=normal>1188</span>
<span class=normal>1189</span>
<span class=normal>1190</span>
<span class=normal>1191</span>
<span class=normal>1192</span>
<span class=normal>1193</span>
<span class=normal>1194</span>
<span class=normal>1195</span>
<span class=normal>1196</span>
<span class=normal>1197</span>
<span class=normal>1198</span>
<span class=normal>1199</span>
<span class=normal>1200</span>
<span class=normal>1201</span>
<span class=normal>1202</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>fit_ext2</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>ext</span><span class=p>,</span> <span class=n>n_extern</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Learn a mapping from the internal state space, to an external</span>
<span class=sd>    augmented space (e.g. position).</span>

<span class=sd>    Returns a column-normalized version of (n_states, n_ext), that</span>
<span class=sd>    is, a distribution over states for each extern bin.</span>

<span class=sd>    X : BinnedSpikeTrainArray</span>

<span class=sd>    ext : array-like</span>
<span class=sd>        array of external correlates (n_bins, )</span>
<span class=sd>    n_extern : int</span>
<span class=sd>        number of extern variables, with range 0,.. n_extern-1</span>

<span class=sd>    save : bool</span>
<span class=sd>        stores extern in PoissonHMM if true, discards it if not</span>

<span class=sd>    self.extern_ of size (n_components, n_extern)</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=n>ext_map</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n_extern</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>n_extern</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>n_extern</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>unique</span><span class=p>(</span><span class=n>ext</span><span class=p>))</span>
        <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>ele</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>unique</span><span class=p>(</span><span class=n>ext</span><span class=p>)):</span>
            <span class=n>ext_map</span><span class=p>[</span><span class=n>ele</span><span class=p>]</span> <span class=o>=</span> <span class=n>ii</span>

    <span class=c1># idea: here, ext can be anything, and n_extern should be range</span>
    <span class=c1># we can e.g., define extern correlates {leftrun, rightrun} and</span>
    <span class=c1># fit the mapping. This is not expexted to be good at all for</span>
    <span class=c1># most states, but it could allow us to identify a state or two</span>
    <span class=c1># for which there *might* be a strong predictive relationship.</span>
    <span class=c1># In this way, the binning, etc. should be done external to this</span>
    <span class=c1># function, but it might still make sense to encapsulate it as</span>
    <span class=c1># a helper function inside PoissonHMM?</span>

    <span class=c1># xpos, ypos = get_position(exp_data[&#39;session1&#39;][&#39;posdf&#39;], bst.centers)</span>
    <span class=c1># x0=0; xl=100; n_extern=50</span>
    <span class=c1># xx_left = np.linspace(x0,xl,n_extern+1)</span>
    <span class=c1># xx_mid = np.linspace(x0,xl,n_extern+1)[:-1]; xx_mid += (xx_mid[1]-xx_mid[0])/2</span>
    <span class=c1># ext = np.digitize(xpos, xx_left) - 1 # spatial bin numbers</span>

    <span class=n>extern</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=n>n_extern</span><span class=p>))</span>

    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
        <span class=c1># assume we have a feature matrix</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
            <span class=p>)</span>
        <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=c1># we have a BinnedSpikeTrainArray</span>
        <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
    <span class=n>posteriors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>vstack</span><span class=p>(</span><span class=n>posteriors</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>  <span class=c1># 1D array of states, of length n_bins</span>

    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>posteriors</span><span class=p>)</span> <span class=o>!=</span> <span class=nb>len</span><span class=p>(</span><span class=n>ext</span><span class=p>):</span>
        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;ext must have same length as decoded state sequence!&quot;</span><span class=p>)</span>

    <span class=k>for</span> <span class=n>ii</span><span class=p>,</span> <span class=n>posterior</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>posteriors</span><span class=p>):</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>np</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>ext</span><span class=p>[</span><span class=n>ii</span><span class=p>]):</span>
            <span class=n>extern</span><span class=p>[:,</span> <span class=n>ext_map</span><span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=n>ext</span><span class=p>[</span><span class=n>ii</span><span class=p>])]]</span> <span class=o>+=</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>posterior</span><span class=p>)</span>

    <span class=c1># normalize extern tuning curves:</span>
    <span class=n>colsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>tile</span><span class=p>(</span><span class=n>extern</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>),</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
    <span class=n>colsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>colsum</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=mi>1</span><span class=p>,</span> <span class=n>colsum</span><span class=p>)</span>
    <span class=n>extern</span> <span class=o>=</span> <span class=n>extern</span> <span class=o>/</span> <span class=n>colsum</span>

    <span class=k>return</span> <span class=n>extern</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.get_state_order class="doc doc-heading"> <code class="highlight language-python"><span class=n>get_state_order</span><span class=p>(</span><span class=n>method</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>start_state</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Return a state ordering, optionally using augmented data.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>method</code> </td> <td> <code>(<a class="autorefs autorefs-internal" href=#nelpy.hmmutils.PoissonHMM.transmat>transmat</a>, <span title=mode>mode</span>, <span title=mean>mean</span>)</code> </td> <td> <div class=doc-md-description> <p>Method to use for ordering states. 'transmat' (default) uses the transition matrix. 'mode' or 'mean' use the external mapping (requires self.<em>extern</em>).</p> </div> </td> <td> <code>&#39;transmat&#39;</code> </td> </tr> <tr class=doc-section-item> <td> <code>start_state</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Initial state to begin from (used only if method is 'transmat').</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>neworder</code></td> <td> <code><span title=list>list</span></code> </td> <td> <div class=doc-md-description> <p>List of state indices in the new order.</p> </div> </td> </tr> </tbody> </table> <details class=note open> <summary>Notes</summary> <p>Both 'mode' and 'mean' assume that <em>extern</em> is in sorted order; this is not verified explicitly.</p> </details> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>order</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>get_state_order</span><span class=p>(</span><span class=n>method</span><span class=o>=</span><span class=s2>&quot;transmat&quot;</span><span class=p>)</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>order</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>get_state_order</span><span class=p>(</span><span class=n>method</span><span class=o>=</span><span class=s2>&quot;mode&quot;</span><span class=p>)</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>394</span>
<span class=normal>395</span>
<span class=normal>396</span>
<span class=normal>397</span>
<span class=normal>398</span>
<span class=normal>399</span>
<span class=normal>400</span>
<span class=normal>401</span>
<span class=normal>402</span>
<span class=normal>403</span>
<span class=normal>404</span>
<span class=normal>405</span>
<span class=normal>406</span>
<span class=normal>407</span>
<span class=normal>408</span>
<span class=normal>409</span>
<span class=normal>410</span>
<span class=normal>411</span>
<span class=normal>412</span>
<span class=normal>413</span>
<span class=normal>414</span>
<span class=normal>415</span>
<span class=normal>416</span>
<span class=normal>417</span>
<span class=normal>418</span>
<span class=normal>419</span>
<span class=normal>420</span>
<span class=normal>421</span>
<span class=normal>422</span>
<span class=normal>423</span>
<span class=normal>424</span>
<span class=normal>425</span>
<span class=normal>426</span>
<span class=normal>427</span>
<span class=normal>428</span>
<span class=normal>429</span>
<span class=normal>430</span>
<span class=normal>431</span>
<span class=normal>432</span>
<span class=normal>433</span>
<span class=normal>434</span>
<span class=normal>435</span>
<span class=normal>436</span>
<span class=normal>437</span>
<span class=normal>438</span>
<span class=normal>439</span>
<span class=normal>440</span>
<span class=normal>441</span>
<span class=normal>442</span>
<span class=normal>443</span>
<span class=normal>444</span>
<span class=normal>445</span>
<span class=normal>446</span>
<span class=normal>447</span>
<span class=normal>448</span>
<span class=normal>449</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>get_state_order</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>method</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>start_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Return a state ordering, optionally using augmented data.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    method : {&#39;transmat&#39;, &#39;mode&#39;, &#39;mean&#39;}, optional</span>
<span class=sd>        Method to use for ordering states. &#39;transmat&#39; (default) uses the transition matrix.</span>
<span class=sd>        &#39;mode&#39; or &#39;mean&#39; use the external mapping (requires self._extern_).</span>
<span class=sd>    start_state : int, optional</span>
<span class=sd>        Initial state to begin from (used only if method is &#39;transmat&#39;).</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    neworder : list</span>
<span class=sd>        List of state indices in the new order.</span>

<span class=sd>    Notes</span>
<span class=sd>    -----</span>
<span class=sd>    Both &#39;mode&#39; and &#39;mean&#39; assume that _extern_ is in sorted order; this is not verified explicitly.</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    &gt;&gt;&gt; order = hmm.get_state_order(method=&quot;transmat&quot;)</span>
<span class=sd>    &gt;&gt;&gt; order = hmm.get_state_order(method=&quot;mode&quot;)</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>if</span> <span class=n>method</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>method</span> <span class=o>=</span> <span class=s2>&quot;transmat&quot;</span>

    <span class=n>neworder</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=k>if</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&quot;transmat&quot;</span><span class=p>:</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_order_from_transmat</span><span class=p>(</span><span class=n>start_state</span><span class=o>=</span><span class=n>start_state</span><span class=p>)</span>
    <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&quot;mode&quot;</span><span class=p>:</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>neworder</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>argsort</span><span class=p>()</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>Exception</span><span class=p>(</span>
                <span class=s2>&quot;External mapping does not exist yet.First use PoissonHMM.fit_ext()&quot;</span>
            <span class=p>)</span>
    <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&quot;mean&quot;</span><span class=p>:</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=p>(</span>
                <span class=n>np</span><span class=o>.</span><span class=n>tile</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]),</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
                <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span>
            <span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>argsort</span><span class=p>()</span>
            <span class=n>neworder</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>argsort</span><span class=p>()</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>Exception</span><span class=p>(</span>
                <span class=s2>&quot;External mapping does not exist yet.First use PoissonHMM.fit_ext()&quot;</span>
            <span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
            <span class=s2>&quot;ordering method &#39;&quot;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>method</span><span class=p>)</span> <span class=o>+</span> <span class=s2>&quot;&#39; not supported!&quot;</span>
        <span class=p>)</span>
    <span class=k>return</span> <span class=n>neworder</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.predict class="doc doc-heading"> <code class="highlight language-python"><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Find the most likely state sequence corresponding to <code>X</code>.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>X</code> </td> <td> <code>array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</code> </td> <td> <div class=doc-md-description> <p>Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>lengths</code> </td> <td> <code>array-like of int, shape (n_sequences,)</code> </td> <td> <div class=doc-md-description> <p>Lengths of the individual sequences in <code>X</code>. The sum of these should be <code>n_samples</code>. Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>w</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>state_sequence</code></td> <td> <code>np.ndarray or list of np.ndarray</code> </td> <td> <div class=doc-md-description> <p>Labels for each sample from <code>X</code>.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>state_seq</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>bst</span><span class=p>)</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>state_seq</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>826</span>
<span class=normal>827</span>
<span class=normal>828</span>
<span class=normal>829</span>
<span class=normal>830</span>
<span class=normal>831</span>
<span class=normal>832</span>
<span class=normal>833</span>
<span class=normal>834</span>
<span class=normal>835</span>
<span class=normal>836</span>
<span class=normal>837</span>
<span class=normal>838</span>
<span class=normal>839</span>
<span class=normal>840</span>
<span class=normal>841</span>
<span class=normal>842</span>
<span class=normal>843</span>
<span class=normal>844</span>
<span class=normal>845</span>
<span class=normal>846</span>
<span class=normal>847</span>
<span class=normal>848</span>
<span class=normal>849</span>
<span class=normal>850</span>
<span class=normal>851</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Find the most likely state sequence corresponding to ``X``.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    X : array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>        Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>    lengths : array-like of int, shape (n_sequences,), optional</span>
<span class=sd>        Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>        Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>
<span class=sd>    w : int, optional</span>
<span class=sd>        Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    state_sequence : np.ndarray or list of np.ndarray</span>
<span class=sd>        Labels for each sample from ``X``.</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    &gt;&gt;&gt; state_seq = hmm.predict(bst)</span>
<span class=sd>    &gt;&gt;&gt; state_seq = hmm.predict(X)</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>_</span><span class=p>,</span> <span class=n>state_sequences</span><span class=p>,</span> <span class=n>centers</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>state_sequences</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.predict_proba class="doc doc-heading"> <code class="highlight language-python"><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>returnLengths</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Compute the posterior probability for each state in the model.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>X</code> </td> <td> <code>array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</code> </td> <td> <div class=doc-md-description> <p>Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>lengths</code> </td> <td> <code>array-like of int, shape (n_sequences,)</code> </td> <td> <div class=doc-md-description> <p>Lengths of the individual sequences in <code>X</code>. The sum of these should be <code>n_samples</code>. Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>w</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>returnLengths</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, also return the lengths array.</p> </div> </td> <td> <code>False</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>posteriors</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Array of shape (n_components, n_samples) with state-membership probabilities for each sample from <code>X</code>.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>lengths</code></td> <td> <code>(<span title=numpy.ndarray>ndarray</span>, <span title=optional>optional</span>)</code> </td> <td> <div class=doc-md-description> <p>Returned if returnLengths is True; array of sequence lengths.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>posteriors</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>bst</span><span class=p>)</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>posteriors</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>bst</span><span class=p>,</span> <span class=n>returnLengths</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>775</span>
<span class=normal>776</span>
<span class=normal>777</span>
<span class=normal>778</span>
<span class=normal>779</span>
<span class=normal>780</span>
<span class=normal>781</span>
<span class=normal>782</span>
<span class=normal>783</span>
<span class=normal>784</span>
<span class=normal>785</span>
<span class=normal>786</span>
<span class=normal>787</span>
<span class=normal>788</span>
<span class=normal>789</span>
<span class=normal>790</span>
<span class=normal>791</span>
<span class=normal>792</span>
<span class=normal>793</span>
<span class=normal>794</span>
<span class=normal>795</span>
<span class=normal>796</span>
<span class=normal>797</span>
<span class=normal>798</span>
<span class=normal>799</span>
<span class=normal>800</span>
<span class=normal>801</span>
<span class=normal>802</span>
<span class=normal>803</span>
<span class=normal>804</span>
<span class=normal>805</span>
<span class=normal>806</span>
<span class=normal>807</span>
<span class=normal>808</span>
<span class=normal>809</span>
<span class=normal>810</span>
<span class=normal>811</span>
<span class=normal>812</span>
<span class=normal>813</span>
<span class=normal>814</span>
<span class=normal>815</span>
<span class=normal>816</span>
<span class=normal>817</span>
<span class=normal>818</span>
<span class=normal>819</span>
<span class=normal>820</span>
<span class=normal>821</span>
<span class=normal>822</span>
<span class=normal>823</span>
<span class=normal>824</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>returnLengths</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Compute the posterior probability for each state in the model.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    X : array-like of shape (n_samples, n_features) or BinnedSpikeTrainArray</span>
<span class=sd>        Feature matrix of individual samples, or a nelpy.BinnedSpikeTrainArray.</span>
<span class=sd>    lengths : array-like of int, shape (n_sequences,), optional</span>
<span class=sd>        Lengths of the individual sequences in ``X``. The sum of these should be ``n_samples``.</span>
<span class=sd>        Not used when X is a BinnedSpikeTrainArray, in which case the lengths are automatically inferred.</span>
<span class=sd>    w : int, optional</span>
<span class=sd>        Window size for sliding window decoding (only used for BinnedSpikeTrainArray input).</span>
<span class=sd>    returnLengths : bool, optional</span>
<span class=sd>        If True, also return the lengths array.</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    posteriors : np.ndarray</span>
<span class=sd>        Array of shape (n_components, n_samples) with state-membership probabilities for each sample from ``X``.</span>
<span class=sd>    lengths : np.ndarray, optional</span>
<span class=sd>        Returned if returnLengths is True; array of sequence lengths.</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    &gt;&gt;&gt; posteriors = hmm.predict_proba(bst)</span>
<span class=sd>    &gt;&gt;&gt; posteriors, lengths = hmm.predict_proba(bst, returnLengths=True)</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;we have a &quot;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>X</span><span class=p>)))</span>
        <span class=c1># assume we have a feature matrix</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
            <span class=p>)</span>
        <span class=k>if</span> <span class=n>returnLengths</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
            <span class=p>),</span> <span class=n>lengths</span>
        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>))</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=c1># we have a BinnedSpikeTrainArray</span>
        <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>returnLengths</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
            <span class=p>),</span> <span class=n>lengths</span>
        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
        <span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.reorder_states class="doc doc-heading"> <code class="highlight language-python"><span class=n>reorder_states</span><span class=p>(</span><span class=n>neworder</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Reorder internal HMM states according to a specified order.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>neworder</code> </td> <td> <code><span title=list>list</span> or <span title=array>array</span> - <span title=like>like</span></code> </td> <td> <div class=doc-md-description> <p>List of state indices specifying the new order. Must be of size (n_components,).</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>hmm</span><span class=o>.</span><span class=n>reorder_states</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>491</span>
<span class=normal>492</span>
<span class=normal>493</span>
<span class=normal>494</span>
<span class=normal>495</span>
<span class=normal>496</span>
<span class=normal>497</span>
<span class=normal>498</span>
<span class=normal>499</span>
<span class=normal>500</span>
<span class=normal>501</span>
<span class=normal>502</span>
<span class=normal>503</span>
<span class=normal>504</span>
<span class=normal>505</span>
<span class=normal>506</span>
<span class=normal>507</span>
<span class=normal>508</span>
<span class=normal>509</span>
<span class=normal>510</span>
<span class=normal>511</span>
<span class=normal>512</span>
<span class=normal>513</span>
<span class=normal>514</span>
<span class=normal>515</span>
<span class=normal>516</span>
<span class=normal>517</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>reorder_states</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>neworder</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Reorder internal HMM states according to a specified order.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    neworder : list or array-like</span>
<span class=sd>        List of state indices specifying the new order. Must be of size (n_components,).</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    &gt;&gt;&gt; hmm.reorder_states([2, 0, 1])</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>oldorder</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>neworder</span><span class=p>)))</span>
    <span class=k>for</span> <span class=n>oi</span><span class=p>,</span> <span class=n>ni</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>neworder</span><span class=p>):</span>
        <span class=n>frm</span> <span class=o>=</span> <span class=n>oldorder</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>ni</span><span class=p>)</span>
        <span class=n>to</span> <span class=o>=</span> <span class=n>oi</span>
        <span class=n>swap_cols</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>transmat_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
        <span class=n>swap_rows</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>transmat_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
        <span class=n>swap_rows</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>means_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>swap_rows</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_extern_</span><span class=p>,</span> <span class=n>frm</span><span class=p>,</span> <span class=n>to</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>[</span><span class=n>to</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>[</span><span class=n>to</span><span class=p>],</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>startprob_</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span>
        <span class=p>)</span>
        <span class=n>oldorder</span><span class=p>[</span><span class=n>frm</span><span class=p>],</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>to</span><span class=p>]</span> <span class=o>=</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>to</span><span class=p>],</span> <span class=n>oldorder</span><span class=p>[</span><span class=n>frm</span><span class=p>]</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.sample class="doc doc-heading"> <code class="highlight language-python"><span class=n>sample</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Generate random samples from the model.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>n_samples</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of samples to generate.</p> </div> </td> <td> <code>1</code> </td> </tr> <tr class=doc-section-item> <td> <code>random_state</code> </td> <td> <code><span title=RandomState>RandomState</span> or <span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>A random number generator instance or seed. If None, the object's random_state is used.</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>X</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Feature matrix of shape (n_samples, n_features).</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>state_sequence</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>State sequence produced by the model.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=n>X</span><span class=p>,</span> <span class=n>states</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>853</span>
<span class=normal>854</span>
<span class=normal>855</span>
<span class=normal>856</span>
<span class=normal>857</span>
<span class=normal>858</span>
<span class=normal>859</span>
<span class=normal>860</span>
<span class=normal>861</span>
<span class=normal>862</span>
<span class=normal>863</span>
<span class=normal>864</span>
<span class=normal>865</span>
<span class=normal>866</span>
<span class=normal>867</span>
<span class=normal>868</span>
<span class=normal>869</span>
<span class=normal>870</span>
<span class=normal>871</span>
<span class=normal>872</span>
<span class=normal>873</span>
<span class=normal>874</span>
<span class=normal>875</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>sample</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_samples</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Generate random samples from the model.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    n_samples : int</span>
<span class=sd>        Number of samples to generate.</span>
<span class=sd>    random_state : RandomState or int, optional</span>
<span class=sd>        A random number generator instance or seed. If None, the object&#39;s random_state is used.</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    X : np.ndarray</span>
<span class=sd>        Feature matrix of shape (n_samples, n_features).</span>
<span class=sd>    state_sequence : np.ndarray</span>
<span class=sd>        State sequence produced by the model.</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    &gt;&gt;&gt; X, states = hmm.sample(n_samples=100)</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sample</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_samples</span><span class=o>=</span><span class=n>n_samples</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=n>random_state</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.score class="doc doc-heading"> <code class="highlight language-python"><span class=n>score</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Compute the log probability under the model.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>X</code> </td> <td> <code>(<span title=array>array</span> - <span title=like>like</span>, <span title=shape>shape</span>(<span title=n_samples>n_samples</span>, <span title=n_features>n_features</span>))</code> </td> <td> <div class=doc-md-description> <p>Feature matrix of individual samples. OR nelpy.BinnedSpikeTrainArray</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>lengths</code> </td> <td> <code>array-like of integers, shape (n_sequences, )</code> </td> <td> <div class=doc-md-description> <p>Lengths of the individual sequences in <code>X</code>. The sum of these should be <code>n_samples</code>. This is not used when X is a nelpy.BinnedSpikeTrainArray, in which case the lenghts are automatically inferred.</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>logprob</code></td> <td> <code>float, or list of floats</code> </td> <td> <div class=doc-md-description> <p>Log likelihood of <code>X</code>; one scalar for each sequence in X.</p> </div> </td> </tr> </tbody> </table> <details class=see-also open> <summary>See Also</summary> <p>score_samples : Compute the log probability under the model and posteriors. decode : Find most likely state sequence corresponding to <code>X</code>.</p> </details> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>931</span>
<span class=normal>932</span>
<span class=normal>933</span>
<span class=normal>934</span>
<span class=normal>935</span>
<span class=normal>936</span>
<span class=normal>937</span>
<span class=normal>938</span>
<span class=normal>939</span>
<span class=normal>940</span>
<span class=normal>941</span>
<span class=normal>942</span>
<span class=normal>943</span>
<span class=normal>944</span>
<span class=normal>945</span>
<span class=normal>946</span>
<span class=normal>947</span>
<span class=normal>948</span>
<span class=normal>949</span>
<span class=normal>950</span>
<span class=normal>951</span>
<span class=normal>952</span>
<span class=normal>953</span>
<span class=normal>954</span>
<span class=normal>955</span>
<span class=normal>956</span>
<span class=normal>957</span>
<span class=normal>958</span>
<span class=normal>959</span>
<span class=normal>960</span>
<span class=normal>961</span>
<span class=normal>962</span>
<span class=normal>963</span>
<span class=normal>964</span>
<span class=normal>965</span>
<span class=normal>966</span>
<span class=normal>967</span>
<span class=normal>968</span>
<span class=normal>969</span>
<span class=normal>970</span>
<span class=normal>971</span>
<span class=normal>972</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Compute the log probability under the model.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    X : array-like, shape (n_samples, n_features)</span>
<span class=sd>        Feature matrix of individual samples.</span>
<span class=sd>        OR</span>
<span class=sd>        nelpy.BinnedSpikeTrainArray</span>
<span class=sd>    lengths : array-like of integers, shape (n_sequences, ), optional</span>
<span class=sd>        Lengths of the individual sequences in ``X``. The sum of</span>
<span class=sd>        these should be ``n_samples``. This is not used when X is</span>
<span class=sd>        a nelpy.BinnedSpikeTrainArray, in which case the lenghts are</span>
<span class=sd>        automatically inferred.</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    logprob : float, or list of floats</span>
<span class=sd>        Log likelihood of ``X``; one scalar for each sequence in X.</span>

<span class=sd>    See Also</span>
<span class=sd>    --------</span>
<span class=sd>    score_samples : Compute the log probability under the model and</span>
<span class=sd>        posteriors.</span>
<span class=sd>    decode : Find most likely state sequence corresponding to ``X``.</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
        <span class=c1># assume we have a feature matrix</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
            <span class=p>)</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=c1># we have a BinnedSpikeTrainArray</span>
        <span class=n>logprobs</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
            <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>seq</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
            <span class=n>logprob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
            <span class=n>logprobs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>logprob</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>logprobs</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=nelpy.hmmutils.PoissonHMM.score_samples class="doc doc-heading"> <code class="highlight language-python"><span class=n>score_samples</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> </h3> <div class="doc doc-contents "> <p>Compute the log probability under the model and compute posteriors.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>X</code> </td> <td> <code>(<span title=array>array</span> - <span title=like>like</span>, <span title=shape>shape</span>(<span title=n_samples>n_samples</span>, <span title=n_features>n_features</span>))</code> </td> <td> <div class=doc-md-description> <p>Feature matrix of individual samples. OR nelpy.BinnedSpikeTrainArray</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>lengths</code> </td> <td> <code>array-like of integers, shape (n_sequences, )</code> </td> <td> <div class=doc-md-description> <p>Lengths of the individual sequences in <code>X</code>. The sum of these should be <code>n_samples</code>. This is not used when X is a nelpy.BinnedSpikeTrainArray, in which case the lenghts are automatically inferred.</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>logprob</code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Log likelihood of <code>X</code>; one scalar for each sequence in X.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>posteriors</code></td> <td> <code>(<span title=array>array</span>, <span title=shape>shape</span>(<span title=n_components>n_components</span>, <span title=n_samples>n_samples</span>))</code> </td> <td> <div class=doc-md-description> <p>State-membership probabilities for each sample in <code>X</code>; one array for each sequence in X.</p> </div> </td> </tr> </tbody> </table> <details class=see-also open> <summary>See Also</summary> <p>score : Compute the log probability under the model. decode : Find most likely state sequence corresponding to <code>X</code>.</p> </details> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>877</span>
<span class=normal>878</span>
<span class=normal>879</span>
<span class=normal>880</span>
<span class=normal>881</span>
<span class=normal>882</span>
<span class=normal>883</span>
<span class=normal>884</span>
<span class=normal>885</span>
<span class=normal>886</span>
<span class=normal>887</span>
<span class=normal>888</span>
<span class=normal>889</span>
<span class=normal>890</span>
<span class=normal>891</span>
<span class=normal>892</span>
<span class=normal>893</span>
<span class=normal>894</span>
<span class=normal>895</span>
<span class=normal>896</span>
<span class=normal>897</span>
<span class=normal>898</span>
<span class=normal>899</span>
<span class=normal>900</span>
<span class=normal>901</span>
<span class=normal>902</span>
<span class=normal>903</span>
<span class=normal>904</span>
<span class=normal>905</span>
<span class=normal>906</span>
<span class=normal>907</span>
<span class=normal>908</span>
<span class=normal>909</span>
<span class=normal>910</span>
<span class=normal>911</span>
<span class=normal>912</span>
<span class=normal>913</span>
<span class=normal>914</span>
<span class=normal>915</span>
<span class=normal>916</span>
<span class=normal>917</span>
<span class=normal>918</span>
<span class=normal>919</span>
<span class=normal>920</span>
<span class=normal>921</span>
<span class=normal>922</span>
<span class=normal>923</span>
<span class=normal>924</span>
<span class=normal>925</span>
<span class=normal>926</span>
<span class=normal>927</span>
<span class=normal>928</span>
<span class=normal>929</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>score_samples</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Compute the log probability under the model and compute posteriors.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    X : array-like, shape (n_samples, n_features)</span>
<span class=sd>        Feature matrix of individual samples.</span>
<span class=sd>        OR</span>
<span class=sd>        nelpy.BinnedSpikeTrainArray</span>
<span class=sd>    lengths : array-like of integers, shape (n_sequences, ), optional</span>
<span class=sd>        Lengths of the individual sequences in ``X``. The sum of</span>
<span class=sd>        these should be ``n_samples``. This is not used when X is</span>
<span class=sd>        a nelpy.BinnedSpikeTrainArray, in which case the lenghts are</span>
<span class=sd>        automatically inferred.</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    logprob : float</span>
<span class=sd>        Log likelihood of ``X``; one scalar for each sequence in X.</span>

<span class=sd>    posteriors : array, shape (n_components, n_samples)</span>
<span class=sd>        State-membership probabilities for each sample in ``X``;</span>
<span class=sd>        one array for each sequence in X.</span>

<span class=sd>    See Also</span>
<span class=sd>    --------</span>
<span class=sd>    score : Compute the log probability under the model.</span>
<span class=sd>    decode : Find most likely state sequence corresponding to ``X``.</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>BinnedSpikeTrainArray</span><span class=p>):</span>
        <span class=c1># assume we have a feature matrix</span>
        <span class=k>if</span> <span class=n>w</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span>
                <span class=s2>&quot;sliding window decoding for feature matrices not yet implemented!&quot;</span>
            <span class=p>)</span>
        <span class=n>logprobs</span><span class=p>,</span> <span class=n>posteriors</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score_samples</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span><span class=p>)</span>
        <span class=k>return</span> <span class=p>(</span>
            <span class=n>logprobs</span><span class=p>,</span>
            <span class=n>posteriors</span><span class=p>,</span>
        <span class=p>)</span>  <span class=c1># .T why does this transpose affect hmm.predict_proba!!!????</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=c1># we have a BinnedSpikeTrainArray</span>
        <span class=n>logprobs</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=n>posteriors</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>
            <span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_sliding_window_array</span><span class=p>(</span><span class=n>bst</span><span class=o>=</span><span class=n>seq</span><span class=p>,</span> <span class=n>w</span><span class=o>=</span><span class=n>w</span><span class=p>)</span>
            <span class=n>logprob</span><span class=p>,</span> <span class=n>posterior</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_score_samples</span><span class=p>(</span>
                <span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>windowed_arr</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>lengths</span>
            <span class=p>)</span>
            <span class=n>logprobs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>logprob</span><span class=p>)</span>
            <span class=n>posteriors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>posterior</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>logprobs</span><span class=p>,</span> <span class=n>posteriors</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-function"> <h2 id=nelpy.hmmutils.estimate_model_quality class="doc doc-heading"> <code class="highlight language-python"><span class=n>estimate_model_quality</span><span class=p>(</span><span class=n>bst</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>hmm</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>n_states</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>n_shuffles</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>k_folds</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;timeswap-pooled&#39;</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span></code> </h2> <div class="doc doc-contents "> <p>Estimate the HMM 'model quality' associated with the set of events in bst.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>bst</code> </td> <td> <code><a class="autorefs autorefs-internal" href=../core/eventarray/#nelpy.core._eventarray.BinnedSpikeTrainArray>BinnedSpikeTrainArray</a></code> </td> <td> <div class=doc-md-description> <p>The binned spike train array containing the events to evaluate.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>hmm</code> </td> <td> <code><a class="autorefs autorefs-internal" href=#nelpy.hmmutils.PoissonHMM>PoissonHMM</a></code> </td> <td> <div class=doc-md-description> <p>An existing HMM model to use. If None, a new model is fit for each fold.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>n_states</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of hidden states in the HMM. If None and hmm is provided, uses hmm.n_components.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>n_shuffles</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of shuffles to perform for the null distribution. Default is 1000.</p> </div> </td> <td> <code>1000</code> </td> </tr> <tr class=doc-section-item> <td> <code>k_folds</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of cross-validation folds. Default is 5.</p> </div> </td> <td> <code>5</code> </td> </tr> <tr class=doc-section-item> <td> <code>mode</code> </td> <td> <code>(<span title=timeswap>timeswap</span> - <span title=pooled>pooled</span>, <span title=timeswap>timeswap</span> - <span title=within>within</span> - <span title=event>event</span>, <span title=temporal>temporal</span> - <span title=within>within</span> - <span title=event>event</span>)</code> </td> <td> <div class=doc-md-description> <p>Shuffling mode to use for generating the null distribution. Default is 'timeswap-pooled'.</p> </div> </td> <td> <code>&#39;timeswap-pooled&#39;</code> </td> </tr> <tr class=doc-section-item> <td> <code>verbose</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, print progress information. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>quality</code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Z-score of the model quality compared to the shuffled null distribution.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>scores</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Array of log-likelihood scores for each fold.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code>shuffled</code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Array of log-likelihood scores for each shuffle and fold.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><span class=gp>&gt;&gt;&gt; </span><span class=kn>from</span><span class=w> </span><span class=nn>nelpy.hmmutils</span><span class=w> </span><span class=kn>import</span> <span class=n>estimate_model_quality</span>
<span class=gp>&gt;&gt;&gt; </span><span class=n>quality</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>shuffled</span> <span class=o>=</span> <span class=n>estimate_model_quality</span><span class=p>(</span>
<span class=gp>... </span>    <span class=n>bst</span><span class=p>,</span> <span class=n>n_states</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>n_shuffles</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>k_folds</span><span class=o>=</span><span class=mi>5</span>
<span class=gp>... </span><span class=p>)</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>nelpy/hmmutils.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 30</span>
<span class=normal> 31</span>
<span class=normal> 32</span>
<span class=normal> 33</span>
<span class=normal> 34</span>
<span class=normal> 35</span>
<span class=normal> 36</span>
<span class=normal> 37</span>
<span class=normal> 38</span>
<span class=normal> 39</span>
<span class=normal> 40</span>
<span class=normal> 41</span>
<span class=normal> 42</span>
<span class=normal> 43</span>
<span class=normal> 44</span>
<span class=normal> 45</span>
<span class=normal> 46</span>
<span class=normal> 47</span>
<span class=normal> 48</span>
<span class=normal> 49</span>
<span class=normal> 50</span>
<span class=normal> 51</span>
<span class=normal> 52</span>
<span class=normal> 53</span>
<span class=normal> 54</span>
<span class=normal> 55</span>
<span class=normal> 56</span>
<span class=normal> 57</span>
<span class=normal> 58</span>
<span class=normal> 59</span>
<span class=normal> 60</span>
<span class=normal> 61</span>
<span class=normal> 62</span>
<span class=normal> 63</span>
<span class=normal> 64</span>
<span class=normal> 65</span>
<span class=normal> 66</span>
<span class=normal> 67</span>
<span class=normal> 68</span>
<span class=normal> 69</span>
<span class=normal> 70</span>
<span class=normal> 71</span>
<span class=normal> 72</span>
<span class=normal> 73</span>
<span class=normal> 74</span>
<span class=normal> 75</span>
<span class=normal> 76</span>
<span class=normal> 77</span>
<span class=normal> 78</span>
<span class=normal> 79</span>
<span class=normal> 80</span>
<span class=normal> 81</span>
<span class=normal> 82</span>
<span class=normal> 83</span>
<span class=normal> 84</span>
<span class=normal> 85</span>
<span class=normal> 86</span>
<span class=normal> 87</span>
<span class=normal> 88</span>
<span class=normal> 89</span>
<span class=normal> 90</span>
<span class=normal> 91</span>
<span class=normal> 92</span>
<span class=normal> 93</span>
<span class=normal> 94</span>
<span class=normal> 95</span>
<span class=normal> 96</span>
<span class=normal> 97</span>
<span class=normal> 98</span>
<span class=normal> 99</span>
<span class=normal>100</span>
<span class=normal>101</span>
<span class=normal>102</span>
<span class=normal>103</span>
<span class=normal>104</span>
<span class=normal>105</span>
<span class=normal>106</span>
<span class=normal>107</span>
<span class=normal>108</span>
<span class=normal>109</span>
<span class=normal>110</span>
<span class=normal>111</span>
<span class=normal>112</span>
<span class=normal>113</span>
<span class=normal>114</span>
<span class=normal>115</span>
<span class=normal>116</span>
<span class=normal>117</span>
<span class=normal>118</span>
<span class=normal>119</span>
<span class=normal>120</span>
<span class=normal>121</span>
<span class=normal>122</span>
<span class=normal>123</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>estimate_model_quality</span><span class=p>(</span>
    <span class=n>bst</span><span class=p>,</span>
    <span class=o>*</span><span class=p>,</span>
    <span class=n>hmm</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
    <span class=n>n_states</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
    <span class=n>n_shuffles</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
    <span class=n>k_folds</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
    <span class=n>mode</span><span class=o>=</span><span class=s2>&quot;timeswap-pooled&quot;</span><span class=p>,</span>
    <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
<span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Estimate the HMM &#39;model quality&#39; associated with the set of events in bst.</span>

<span class=sd>    Parameters</span>
<span class=sd>    ----------</span>
<span class=sd>    bst : BinnedSpikeTrainArray</span>
<span class=sd>        The binned spike train array containing the events to evaluate.</span>
<span class=sd>    hmm : PoissonHMM, optional</span>
<span class=sd>        An existing HMM model to use. If None, a new model is fit for each fold.</span>
<span class=sd>    n_states : int, optional</span>
<span class=sd>        Number of hidden states in the HMM. If None and hmm is provided, uses hmm.n_components.</span>
<span class=sd>    n_shuffles : int, optional</span>
<span class=sd>        Number of shuffles to perform for the null distribution. Default is 1000.</span>
<span class=sd>    k_folds : int, optional</span>
<span class=sd>        Number of cross-validation folds. Default is 5.</span>
<span class=sd>    mode : {&#39;timeswap-pooled&#39;, &#39;timeswap-within-event&#39;, &#39;temporal-within-event&#39;}, optional</span>
<span class=sd>        Shuffling mode to use for generating the null distribution. Default is &#39;timeswap-pooled&#39;.</span>
<span class=sd>    verbose : bool, optional</span>
<span class=sd>        If True, print progress information. Default is False.</span>

<span class=sd>    Returns</span>
<span class=sd>    -------</span>
<span class=sd>    quality : float</span>
<span class=sd>        Z-score of the model quality compared to the shuffled null distribution.</span>
<span class=sd>    scores : np.ndarray</span>
<span class=sd>        Array of log-likelihood scores for each fold.</span>
<span class=sd>    shuffled : np.ndarray</span>
<span class=sd>        Array of log-likelihood scores for each shuffle and fold.</span>

<span class=sd>    Examples</span>
<span class=sd>    --------</span>
<span class=sd>    &gt;&gt;&gt; from nelpy.hmmutils import estimate_model_quality</span>
<span class=sd>    &gt;&gt;&gt; quality, scores, shuffled = estimate_model_quality(</span>
<span class=sd>    ...     bst, n_states=3, n_shuffles=100, k_folds=5</span>
<span class=sd>    ... )</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>zmap</span>

    <span class=kn>from</span><span class=w> </span><span class=nn>.decoding</span><span class=w> </span><span class=kn>import</span> <span class=n>k_fold_cross_validation</span>

    <span class=k>if</span> <span class=n>hmm</span><span class=p>:</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>n_states</span><span class=p>:</span>
            <span class=n>n_states</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>n_components</span>

    <span class=n>X</span> <span class=o>=</span> <span class=p>[</span><span class=n>ii</span> <span class=k>for</span> <span class=n>ii</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>bst</span><span class=o>.</span><span class=n>n_epochs</span><span class=p>)]</span>

    <span class=n>scores</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>bst</span><span class=o>.</span><span class=n>n_epochs</span><span class=p>)</span>
    <span class=n>shuffled</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>bst</span><span class=o>.</span><span class=n>n_epochs</span><span class=p>,</span> <span class=n>n_shuffles</span><span class=p>))</span>

    <span class=k>if</span> <span class=n>mode</span> <span class=o>==</span> <span class=s2>&quot;timeswap-pooled&quot;</span><span class=p>:</span>
        <span class=c1># shuffle data coherently, pooled over all events:</span>
        <span class=n>shuffle_func</span> <span class=o>=</span> <span class=n>replay</span><span class=o>.</span><span class=n>pooled_time_swap_bst</span>
    <span class=k>elif</span> <span class=n>mode</span> <span class=o>==</span> <span class=s2>&quot;timeswap-within-event&quot;</span><span class=p>:</span>
        <span class=c1># shuffle data coherently within events:</span>
        <span class=n>shuffle_func</span> <span class=o>=</span> <span class=n>replay</span><span class=o>.</span><span class=n>time_swap_bst</span>
    <span class=k>elif</span> <span class=n>mode</span> <span class=o>==</span> <span class=s2>&quot;temporal-within-event&quot;</span><span class=p>:</span>
        <span class=n>shuffle_func</span> <span class=o>=</span> <span class=n>replay</span><span class=o>.</span><span class=n>incoherent_shuffle_bst</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=k>raise</span> <span class=ne>NotImplementedError</span>

    <span class=k>for</span> <span class=n>kk</span><span class=p>,</span> <span class=p>(</span><span class=n>training</span><span class=p>,</span> <span class=n>validation</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>k_fold_cross_validation</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=n>k_folds</span><span class=p>)):</span>
        <span class=k>if</span> <span class=n>verbose</span><span class=p>:</span>
            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;  fold </span><span class=si>{}</span><span class=s2>/</span><span class=si>{}</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>kk</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>k_folds</span><span class=p>))</span>

        <span class=n>PBEs_train</span> <span class=o>=</span> <span class=n>bst</span><span class=p>[</span><span class=n>training</span><span class=p>]</span>
        <span class=n>PBEs_test</span> <span class=o>=</span> <span class=n>bst</span><span class=p>[</span><span class=n>validation</span><span class=p>]</span>

        <span class=c1># train HMM on all training PBEs</span>
        <span class=n>hmm</span> <span class=o>=</span> <span class=n>PoissonHMM</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=n>n_states</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
        <span class=n>hmm</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>PBEs_train</span><span class=p>)</span>

        <span class=c1># compute scores_hmm (log likelihoods) of validation set:</span>
        <span class=n>scores</span><span class=p>[</span><span class=n>validation</span><span class=p>]</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>PBEs_test</span><span class=p>)</span>

        <span class=k>for</span> <span class=n>nn</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_shuffles</span><span class=p>):</span>
            <span class=c1># shuffle data:</span>
            <span class=n>bst_test_shuffled</span> <span class=o>=</span> <span class=n>shuffle_func</span><span class=p>(</span><span class=n>PBEs_test</span><span class=p>)</span>

            <span class=c1># score validation set with shuffled-data HMM</span>
            <span class=n>shuffled</span><span class=p>[</span><span class=n>validation</span><span class=p>,</span> <span class=n>nn</span><span class=p>]</span> <span class=o>=</span> <span class=n>hmm</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>bst_test_shuffled</span><span class=p>)</span>

    <span class=n>quality</span> <span class=o>=</span> <span class=n>zmap</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span> <span class=n>shuffled</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span>

    <span class=k>return</span> <span class=n>quality</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>shuffled</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../preprocessing/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Preprocessing"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Preprocessing </div> </div> </a> <a href=../../tutorials/GettingStarted/ class="md-footer__link md-footer__link--next" aria-label="Next: Getting Started"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Getting Started </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "content.tabs.link", "navigation.footer", "navigation.indexes", "navigation.instant.prefetch", "navigation.instant.preview", "navigation.instant.progress", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.50899def.min.js></script> </body> </html>